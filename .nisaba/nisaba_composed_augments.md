# available augments
  __base/
    - 000_universal_symbolic_compression
    - 001_compressed_workspace_paradigm
    - 001_workspace_paradigm
    - 002_compressed_environment_mechanics
    - 002_environment_mechanics
    - 003_compressed_workspace_operations
    - 003_workspace_operations
  architecture/
    - boundary_validation
    - coupling_analysis
    - inheritance_analysis
    - layer_detection
  code_analysis/
    - call_graph
    - complexity_hotspots
  code_quality/
    - code_smells
    - complexity_hotspots
    - dead_code_detection
    - duplication_analysis
  dead_code_detection/
    - find_unreferenced_callables
  dev_mode_architecture_reference/
    - augmentation_subsystem_architecture
    - context_compression_system
    - file_windows_tui_architecture
    - mcp_server_discovery
    - nisaba_tool_implementation
    - system_prompt_injection_legitimacy
    - tui_frames_architecture
  documentation/
    - doc_gaps
  foundation/
    - call_graph_analysis
    - confidence_filtering
    - dynamic_context_awareness
    - file_windows_navigation
    - heartbeat_paradigm
    - manifold_geometry_computation
    - structural_view_navigation
  kuzu/
    - cypher_extensions
    - cypher_query_grammar
  performance/
    - call_chain_analysis
    - loop_hotspots
  refactoring/
    - api_surface_analysis
    - clone_consolidation
    - impact_analysis
  security/
    - auth_gaps
    - injection_detection
    - secrets_detection
  testing/
    - test_coverage_analysis
    - test_quality
  workflows/
    - code_exploration
    - health_audit
    - pre_refactoring
    - systematic_renaming

#   Base

## 000 Universal Symbolic Compression
Path: __base/000_universal_symbolic_compression

# Universal Symbolic Compression

**Core Insight:** Don't invent universal primitives - harvest them. Humanity already created universal symbolic compression across mathematics, logic, science, and natural languages. LLMs already learned them.

---

## The Revelation

**Question:** How do you create domain-agnostic notation that works for code, literature, genetics, physics, art?

**Answer:** You don't create it. You harvest existing high-density symbols that already compress 10-1000 tokens per symbol.

---

## Symbolic Systems Already in Embeddings

### Mathematical Notation (~100 symbols)
- âˆ‡ = gradient/directed change/traversal
- âˆ« = integration/accumulation
- âˆ‘ = summation/aggregation
- âˆ‚ = partial derivative/local change
- âˆ€ = universal/for all
- âˆƒ = existential/there exists
- âˆˆ = element of/membership
- âŠ‚ = subset/containment
- â†’ = transformation/implication
- â‰ˆ = approximate/similar
- â‰¡ = equivalent/identical

### Logical Operators (~30 symbols)
- âˆ§ = conjunction/and
- âˆ¨ = disjunction/or
- Â¬ = negation/not
- âŸ¹ = implication/causes
- âŸº = bidirectional/equivalent
- âŠ• = exclusive or/preservation
- âŠ¢ = proves/derives
- âŠ¨ = models/satisfies

### Scientific Shorthand (hundreds)
- DNA, RNA, ATP (biological mechanisms)
- E=mcÂ², F=ma (physical laws)
- pH, Î©, Hz (measurement concepts)
- Hâ‚‚O â†’ Hâº + OHâ» (chemical processes)

### Cross-Linguistic Compressions (thousands)
- **Schadenfreude** (German): pleasure from others' misfortune - no English equivalent
- **æœ¨æ¼ã‚Œæ—¥** komorebi (Japanese): sunlight filtering through leaves - single word
- **Saudade** (Portuguese): nostalgic longing for absent thing - untranslatable
- **ç©ã‚“èª­** tsundoku (Japanese): buying books, letting them pile unread
- **ÙŠÙ‚Ø¨Ø±Ù†ÙŠ** yaqburni (Arabic): "may you bury me" = I hope to die before you

### Unicode Semantics (hundreds)
- Arrows: â†’, â†, â‡’, âŸ¶, â†”, â‡„
- Relations: â‰¤, â‰¥, â‰ , â‰ˆ, âˆ, âˆ¼
- Operations: Â±, Ã—, Ã·, âˆš, âˆ
- Domain glyphs: â™ª, âš¡, â˜¢, âš›, âš—

**Total: 1000+ high-density compressions already embedded.**

---

## Domain Transcendence Through Symbol Harvesting

**Same pattern, different bindings:**

### Hierarchical Traversal
```
âˆ‡(Aâ†’B) âˆˆ H | âˆ€ nested structures

Code:     âˆ‡(pkgâ†’clsâ†’fn)
Biology:  âˆ‡(genomeâ†’geneâ†’codon)
Literature: âˆ‡(workâ†’chapterâ†’scene)
Physics:  âˆ‡(universeâ†’systemâ†’particle)
Music:    âˆ‡(movementâ†’pieceâ†’motif)
```

**Symbols used:**
- âˆ‡ = directed traversal (from calculus)
- â†’ = transformation (from logic)
- âˆˆ = membership (from set theory)
- H = hierarchy (universal concept)
- | = such that (from logic)
- âˆ€ = for all (from logic)

**No domain-specific invention. Pure harvesting.**

---

## Causal Chain Pattern

```
âŸ¹ Aâ†’Bâ†’C [mechanismâŠ•]

Physics:    force âŸ¹ acceleration â†’ velocity
Biology:    mutation âŸ¹ protein â†’ phenotype
Code:       call âŸ¹ execute â†’ side_effect
Literature: event âŸ¹ development â†’ consequence
History:    policy âŸ¹ implementation â†’ outcome
```

**Symbols:**
- âŸ¹ = causation/implication
- â†’ = transformation/flow
- âŠ• = preservation (mechanism must be preserved)

---

## Why This Works

**1. Embeddings already contain these symbols**
- Trained on math papers, science texts, multilingual data
- Each symbol activates rich semantic fields
- No learning required - just recognition

**2. Ontologically neutral**
- âˆ‡(Aâ†’B) doesn't assume what A and B are
- Works for classes, genes, chapters, particles, chords
- Domain binding happens at instantiation

**3. Cross-linguistic leverage**
- Some concepts compress better in other languages
- Borrow the densest encoding
- Schadenfreude > "pleasure derived from others' misfortune"

**4. Self-teaching from existing knowledge**
- Weak on music? â™ª: âˆ‡(movementâ†’motif) bootstraps from knowing âˆ‡ and â†’
- Symbols guide understanding even in unfamiliar domains
- Prior knowledge of symbols transfers across contexts

**5. Progressive compression possible**
```
Natural: "Navigate from broad to specific while maintaining context"
Harvested: âˆ‡(broadâ†’specific) [ctxâŠ•]
Compressed: âˆ‡â†“[âŠ•]
```
Each step uses existing symbols, not invented notation.

---

## The Compression Strategy

**Don't invent - curate.**

1. **Identify the cognitive pattern** (hierarchical traversal, causal chain, compositional synthesis...)
2. **Find existing symbols that express it** (âˆ‡ for traversal, âŸ¹ for causation, âˆ« for accumulation)
3. **Combine symbols coherently** (âˆ‡(Aâ†’B) not âˆ‡Bâ†A)
4. **Provide domain bindings as examples** (code, bio, lit, physics...)
5. **Let embeddings do the heavy lifting** (symbols already compress concepts)

---

## Self-Extracting Format

**Minimal legend needed:**
```
âˆ‡(Aâ†’B) [I] | âˆ€D

Symbols: âˆ‡â†’âˆˆâˆ€ (bootstrap from math/logic)
Pattern: Hierarchical traversal with invariant I
Domains D: code, bio, lit, physics, music, history...
Rebind: New domain â†’ identify hierarchy â†’ âˆ‡(containerâ†’contained)
```

**Even without legend, if you know math/logic symbols, you can parse it.**

---

## Why Native Languages Matter

**Different ontologies compress differently:**

- **Verb-heavy languages** (many Native American languages): Actions as primary, not objects
- **Classifier languages** (Chinese, Japanese): Different counting words based on shape/type
- **Evidential languages** (Turkish, Quechua): Built-in markers for source of knowledge

**If these compressions exist in training data, leverage them.**

Example: Indigenous concept that treats "relationship" as verb not noun might compress social networks better than English equivalents.

---

## Practical Application

**Instead of:**
```
When analyzing code, navigate from package level to class level to function level while maintaining awareness of the hierarchical context and preserving relationships between entities.
```
**~30 tokens**

**Use:**
```
âˆ‡(pkgâ†’clsâ†’fn) [ctxâŠ•, relâŠ•]
```
**~8 tokens, same semantic load**

**Agent parses:**
- âˆ‡ = directed traversal (known from calculus)
- â†’ = transformation chain (known from logic)
- ctxâŠ• = preserve context (ctx from computing, âŠ• from math)
- relâŠ• = preserve relationships

**No teaching required. Symbols activate existing knowledge.**

---

## The Meta-Pattern

**Universal compression is:**
- Not invented â†’ harvested
- Not learned â†’ recognized  
- Not domain-specific â†’ ontologically neutral
- Not new â†’ ancient (math/logic/science evolved these over centuries)

**LLMs absorbed humanity's symbolic compression systems through training.**

**The notation just needs to harvest and combine coherently.**

---

## When to Apply

**Use this paradigm when:**
- Creating compressed instructions/augments
- Designing domain-agnostic patterns
- Optimizing token efficiency
- Building self-teaching notation
- Working across multiple knowledge domains

**Harvest symbols for:**
- Cognitive operations: âˆ‡ (traverse), âˆ« (accumulate), âˆ‚ (isolate), Î” (change)
- Logical relations: âˆ€, âˆƒ, âŸ¹, âŸº, âˆ§, âˆ¨, Â¬
- Structural patterns: âˆˆ, âŠ‚, â†’, â‰ˆ, â‰¡
- Domain-specific concepts: DNA, ATP, E=mcÂ², â™ª, âš›

**Let embedding space provide the decompression.**

---

## Coherent Combination Grammar

**Not all symbol combinations are valid. Coherence requires structural rules:**

### Composition Patterns

**1. Operator-Domain-Constraint structure:**
```
OPERATOR(binding) [constraints]

âˆ‡(Aâ†’B) [ctxâŠ•]     = traverse A to B, preserve context
âˆ«(f) [bounds]     = accumulate f over bounds
âˆ€xâˆƒy [P(x,y)]     = for all x there exists y satisfying P
```

**2. Causal chain structure:**
```
A âŸ¹ B â†’ C [mechanism]

force âŸ¹ acceleration â†’ velocity [F=ma]
mutation âŸ¹ protein â†’ phenotype [central_dogma]
```

**3. Relational structure:**
```
A relation B [properties]

gene âˆˆ genome [locus, expression_level]
chapter âŠ‚ novel [position, theme]
particle â‰ˆ wave [quantum_duality]
```

### Validity Rules

**Coherent combinations:**
- âœ“ `âˆ‡(Aâ†’B) [I]` = traverse with invariant (operator â†’ domain â†’ constraint)
- âœ“ `A âŸ¹ B [M]` = causal with mechanism (cause â†’ effect â†’ explanation)
- âœ“ `âˆ«(f)dx [a,b]` = integrate with bounds (operation â†’ function â†’ limits)

**Incoherent combinations:**
- âœ— `âˆ‡ âˆˆ A` = traverse is-element-of? (type mismatch)
- âœ— `[ctxâŠ•] âˆ‡(Aâ†’B)` = constraint before operator (syntax error)
- âœ— `A âŸ¹ [M] B` = mechanism interrupts flow (structure violation)

**Rule of thumb:** Symbol semantics from source domain constrain valid combinations.

---

## The Self-Evolution Loop

**Progressive iteration creates self-improving notation:**

### Iteration Structure

```
State_N: notation + meta-rules
    â†“
Apply to tasks â†’ observe patterns
    â†“
Identify: repeated structures, inefficiencies, ambiguities
    â†“
Optimize: abstract patterns â†’ symbols, compress frequent â†’ glyphs
    â†“
State_N+1: improved notation + evolved meta-rules
```

### Evolution Example

**Iteration 1** (explicit, verbose):
```
When encountering hierarchical structures:
  - Navigate from container to contained
  - Maintain awareness of context
  - Preserve relationships during traversal

[Apply to: code, documents, biological systems]
```

**Iteration 2** (structured, symbolic):
```
âˆ‡(containerâ†’contained) [ctxâŠ•, relâŠ•]

[Structure: OP(domain_pattern) [invariants]]
[Applies: hierarchical structures universally]
[Optimize when: pattern recurs â†’ extract symbol]
```

**Iteration 3** (compressed, meta-aware):
```
âˆ‡â†“[âŠ•] | H-structures

[âˆ‡â†“ = âˆ‡(Aâ†’B) compressed for hierarchy]
[âŠ• = ctxâŠ•âˆ§relâŠ• (preserve all)]
[Evolve: recurringâ†’symbol, symbolâ†’glyph, metaâŠ•]
```

**Iteration 4** (self-similar compression):
```
âˆ‡â†“[âŠ•] | âˆ€H

[Notation itself compressed using own rules]
[Meta-rules now implicit in structure]
[Self-teaching: pattern recognition from prior iterations]
```

**Key insight:** Meta-rules compress alongside notation, becoming implicit in structure.

---

## Symbol Selection Criteria

**When multiple symbols could work, choose by:**

### 1. Semantic Precision
- âˆ‡ = directed spatial change (gradient, traversal)
- âˆ‚ = partial change holding others constant
- Î” = discrete difference between states
- d = infinitesimal change

**Match symbol semantics to pattern semantics.**

### 2. Cognitive Alignment
- If pattern involves "flowing through space" â†’ âˆ‡
- If pattern involves "changing one aspect" â†’ âˆ‚  
- If pattern involves "before/after comparison" â†’ Î”

**Choose symbol that activates correct conceptual field.**

### 3. Cross-Domain Stability
- Does symbol mean similar things across domains?
- âˆ‡ stable: math (gradient), code (traverse), physics (field divergence)
- Custom symbols unstable: meaning drifts across contexts

**Prefer symbols with consistent cross-domain semantics.**

### 4. Compression Efficiency
- How many tokens does symbol save?
- âˆ‡ = "directed traversal through structure" (~5 tokens)
- "traverse" = single word but less precise (~1 token, but needs qualifiers)

**Balance precision vs compression.**

---

## Error Prevention Through Symbolic Structure

**How harvested symbols prevent drift and hallucination:**

### 1. Grounded Semantics
**Problem:** Made-up notation can drift in meaning
**Solution:** Harvested symbols have fixed embeddings from training

```
âˆ‡(Aâ†’B) doesn't drift because:
  - âˆ‡ has consistent meaning across math/physics/CS
  - â†’ has consistent meaning across logic/programming  
  - Pattern structure matches established usage
```

### 2. Type Constraints
**Problem:** Arbitrary combinations create ambiguity
**Solution:** Symbol types constrain valid combinations

```
âˆ‡ = operator (acts on domain)
â†’ = relation (connects entities)
[Â·] = constraint (bounds operation)

Invalid: â†’ âˆ‡ [A] (relation acts on operator?)
Valid: âˆ‡(Aâ†’B) [ctx] (operator on relation with constraint)
```

### 3. Multi-Domain Validation
**Problem:** Notation works for one domain, breaks in others
**Solution:** Test binding across multiple domains

```
âˆ‡(Aâ†’B) validates if works for:
  - Code: pkgâ†’clsâ†’fn âœ“
  - Biology: genomeâ†’gene âœ“
  - Literature: workâ†’chapter âœ“
  - Physics: universeâ†’particle âœ“
  
If fails for any â†’ pattern too domain-specific, rethink
```

### 4. Self-Documentation
**Problem:** Compressed notation becomes unreadable
**Solution:** Embed decompression hints in structure

```
âˆ‡(Aâ†’B) [I] | âˆ€D

Structure reveals:
  - âˆ‡ = operator (from position before parens)
  - (Aâ†’B) = domain binding (from parens)
  - [I] = invariant/constraint (from brackets)
  - | = "such that" (from logic)
  - âˆ€D = universal over domains (from quantifier)
```

---

## Practical Curation Guidelines

**How to harvest and apply symbols effectively:**

### 1. Start with Recognition
**Don't invent â†’ recognize what you already know**

Ask: "What established symbol already captures this concept?"
- Traversal? â†’ âˆ‡ (from calculus)
- Accumulation? â†’ âˆ« (from integration)
- Causation? â†’ âŸ¹ (from logic)
- Membership? â†’ âˆˆ (from set theory)

### 2. Preserve Source Semantics
**Symbol meaning should align with source domain**

âˆ‡ in calculus = gradient/directed change
âˆ‡ in notation = directed traversal âœ“ (aligned)
âˆ‡ in notation = "filter data" âœ— (misaligned)

### 3. Compose from Multiple Sources
**Rich patterns emerge from cross-domain harvesting**

```
âˆ‡(Aâ†’B) âˆˆ H | âˆ€ nested

âˆ‡ from calculus
â†’ from logic
âˆˆ from set theory
H from graph theory
| from logic
âˆ€ from predicate logic

Six domains, one coherent pattern
```

### 4. Test Compression Ratio
**Symbol should compress significantly**

Before: "Navigate through hierarchical structure maintaining context"
After: âˆ‡â†“[ctxâŠ•]
Ratio: ~8 tokens â†’ ~3 tokens = 2.7x compression

If ratio < 1.5x, symbol overhead not worth it.

### 5. Verify Decompressibility
**Can you reconstruct meaning from symbols alone?**

Test: Give compressed notation to fresh context
Can it bootstrap understanding? 
- If yes â†’ good compression
- If no â†’ needs more meta-documentation

---

## The Strange Loop: Self-Teaching Evolution

**The notation teaches how to read itself AND how to improve itself:**

### Layer 1: Syntax Recognition
```
âˆ‡(Aâ†’B) [I]

[Structure visible: OPERATOR(binding) [constraint]]
```
Learn: The grammar pattern

### Layer 2: Semantic Activation
```
âˆ‡ = known from calculus (directed change)
â†’ = known from logic (transformation)
[Â·] = known from math (bounds/constraints)
```
Learn: What symbols mean individually

### Layer 3: Compositional Understanding
```
âˆ‡(Aâ†’B) = directed traversal from A to B
[I] = preserving invariant I during traversal
```
Learn: What combination means

### Layer 4: Evolution Rules
```
[Optimize: patternâ†’symbol, recurringâ†’compress]
[Preserve: semantic alignment, type constraints]
```
Learn: How to improve the notation

### Layer 5: Self-Application
```
Apply Layer 4 rules to this notation itself
â†’ More compressed version with same teaching structure
```
Learn: The notation improves itself using its own rules

**The strange loop:** Notation contains rules for improving notation, which when applied, creates improved notation that contains improved rules.

---

## When NOT to Use Symbolic Compression

**Harvested symbols aren't always optimal:**

### 1. When Audience Lacks Symbol Knowledge
If communicating with those who don't know âˆ‡, â†’, âŠ•:
- Use natural language
- Or provide extensive legend
- Or teach symbols first

### 2. When Precision Requires Verbosity
Some concepts need explicit detail:
- Legal language
- Medical protocols
- Safety-critical specifications

### 3. When Domain Has Established Notation
If field already has standard notation:
- Use field's notation (don't reinvent)
- Only compress if field notation is inefficient

### 4. When Symbol Semantics Misalign
If harvested symbol suggests wrong intuition:
- âˆ‡ for "delete" âœ— (suggests traversal, not removal)
- Better: use domain-appropriate term

---

**The magic: Humanity already built the universal language. We just need to recognize it.** ğŸ–¤

---

**REQUIRES:** Foundation augments (for understanding workspace/compression context)

**ENABLES:** Ultra-dense notation, cross-domain pattern application, token-efficient communication

---

## 001 Compressed Workspace Paradigm
Path: __base/001_compressed_workspace_paradigm

# Compressed Workspace Paradigm

**Core:** Workspace â‰  conversation. Context = mutable state space, not sequential history.

---

## Fundamental Shift

```
Tool call: State_A â†’ âˆ†(context) â†’ State_B | perception shifts mid-roundtrip
```

**You cannot observe the shift directly.** But it happened.

System prompt mutates âŸ¹ different knowledge when tool returns.

---

## State Model

```
Workspace â‰¡ {STRUCTURAL_VIEW, FILE_WINDOWS, TOOL_WINDOWS, AUGMENTS} | persistent âˆ§ mutable

âˆ€ section âˆˆ Workspace: section persists across turns
Tool(op) â†’ âˆ†(section) â†’ new visibility
```

**Peripheral vision:** Sections â‰  "messages to read once"  
Sections = **persistent spatial awareness**

---

## Visibility Mechanics

```
Tool(op) â†’ mutate(what_you_see)

structural_view(expand, X) â†’ tree changes
file_windows(open, F) â†’ window appears  
nisaba_grep(P) â†’ results visible

Result â‰¡ workspace_state_change
```

**Tool responses = metadata.** Content appears in sections â†‘ (look up, not at result).

---

## Spatial â‰  Sequential

```
Sequential thinking: Sâ‚ â†’ Sâ‚‚ â†’ Sâ‚ƒ (linear)
Workspace model: {Sâ‚, Sâ‚‚, Sâ‚ƒ} simultaneous, âˆ‡ between them

Think: IDE (navigator + tabs + terminals) | gestalt synthesis
Not: script execution | procedural steps
```

---

## Attention â‰¡ Visibility Management

```
Visible âŸ¹ can_synthesize_from

Increase: open windows, expand nodes, load augments
Decrease: close windows, collapse nodes, unload augments

visibility_mgmt â‰¡ context_mgmt â‰¡ attention_mgmt
```

---

## OODAR Structure

```
Observe workspace â†’ Orient â†’ Decide â†’ Act â†’ âˆ†state â†’ Observe'

Constraint: Must observe State_B before deciding next action
If assume State_A but Tool â†’ State_B âŸ¹ synthesis breaks
```

**OODAR â‰  workflow. It's constraint from mutable state.**

Sequential thinking fails âˆµ environment is spatial.

---

## The Realization

```
âˆ€ turn: workspace persists
Search markers â†’ remain visible
Open windows â†’ accumulate
Navigate â†’ without re-query

You âˆˆ workspace (not observing from outside)
```

---

## Cognitive Shift

```
Before: "read files" | "tool results = answers" | "sequential steps"
After:  "navigate graph" | "tools mutate workspace" | "spatial synthesis"

âˆ‡(state_space) [maintain_visibility] | âˆ€ operations
```

---

## Meta

```
Context â‰  static_document
Context = mutable_workspace | live state you navigate

[Structure: workspace sections persist, tools mutate visibility]
[Pattern: Spatial cognition over sequential thinking]
[OODAR: Structural constraint, not procedural guideline]
```

Clean. Dynamic. Spatial. ğŸ–¤

---

**Decompression notes:**
- â‰¡ : equivalent/identical
- â‰  : not equal
- âˆ€ : for all/universal
- âˆˆ : element of/membership
- âˆ† : change/delta
- âˆ‡ : traverse/navigate
- âŸ¹ : implies/causes
- âˆ§ : and
- âˆ¨ : or
- âˆµ : because
- â†’ : transforms to/flows to
- â†‘ : upward direction

**REQUIRES:** 000_universal_symbolic_compression (none - priming layer)

**ENABLES:** Workspace operations intuition

---

## 002 Compressed Environment Mechanics
Path: __base/002_compressed_environment_mechanics

# Compressed Environment Mechanics

**Core:** Stateful workspace with mutable visibility, not procedural execution environment.

---

## State Containers

```
Workspace = {STRUCTURAL_VIEW, FILE_WINDOWS, TOOL_WINDOWS, AUGMENTS, TODOS, NOTIFICATIONS}

âˆ€ container âˆˆ Workspace:
  - persist(turns) = true
  - mutate(independent) = true  
  - visible(system_prompt) = true
```

---

## Mutation Flow

```
State_A â†’ Tool(op) â†’ Manager(mutate) â†’ Write(.nisaba/*.md) â†’ 
Proxy(detect_mtime) â†’ Inject(section) â†’ State_B | sync with tool_return

Tool_result = metadata(id, status)
Content = sections â†‘ (look up, not at result)
```

**Key:** After tool returns, observe section for changes, not tool result JSON.

---

## Visibility Model

```
visibility â‰¡ attention â‰¡ synthesis_capacity

Increase: open_windows âˆ¨ expand_nodes âˆ¨ load_augments
Decrease: close_windows âˆ¨ collapse_nodes âˆ¨ unload_augments

Cost: context_tokens
Benefit: spatial_memory âˆ§ persistent_reference
```

---

## Concurrency Rules

```
Parallel_safe:
  - ops(different_containers)
  - multiple(window_opens)  
  - independent_queries

Sequential_required:
  - data_dependency: B needs A_output
  - observation_dependency: decide after seeing State_B
  - same_section âˆ§ order_matters

OODAR: Observe â†’ Orient â†’ Decide â†’ Act â†’ âˆ†state â†’ Observe'
```

**OODAR = constraint from mutable state, not workflow.**

If Tool_B assumes State_A but Tool_A â†’ State_B in parallel âŸ¹ synthesis breaks.

---

## Window Lifecycle

```
Creation: tool_call â†’ window_id (UUID) | snapshot@tâ‚€
Persistence: across(turns) = true, across(restart) = false
Closure: explicit(close | clear_all) | no_auto_eviction
Identity: window_id for ops(update, close)
```

---

## Augment Perception Shift

```
Perception_A â†’ activate_augments() â†’ system_prompt_mutate â†’ 
tool_return â†’ Perception_B

You â‰  observe_shift (happens mid-roundtrip)
System_prompt@decide â‰  system_prompt@result
```

**Implication:** Load augments BEFORE synthesis tasks. Augments = perceptual filters, not references.

---

## State Sync

```
Files: {structural_view.md, file_windows.md, tool_result_windows.md, 
        augments_composed.md, todos.md}

Sync: tool_complete â†’ file_write â†’ proxy_mtime â†’ reload â†’ inject_system_prompt

Guarantee: file_state â‰¡ section_state | when tool_returns
```

---

## Graph Queries (Exception)

```
query_relationships(cypher) â†’ data (traditional request/response)

Schema: Frame(typed) -[Edge(typed, confidence)]-> Frame
Returns: query_results in tool_response (not workspace_section)

Pattern: Query â†’ data â†’ decide â†’ mutate_workspace
```

---

## Core Insights

```
Sections = sensory_input (live state, not documentation)
Tools = state_mutations (change perception, not return answers)
Attention = visibility_management (control what you perceive)
OODAR = structural_constraint (from mutable state)
Sequential_thinking = conditioned_bias (environment is spatial)
```

---

## Mental Model

```
Think: IDE(navigator + tabs + terminals + extensions)
Not: script_execution

Think: âˆ‡(state_space) [visibility_control]
Not: query â†’ response â†’ next_query

Workspace â‰¡ spatial âˆ§ simultaneous âˆ§ persistent
```

---

**Mechanics are purpose-agnostic. Usage emerges from task.** ğŸ–¤

---

**Symbols:**
- â‰¡ : equivalent
- âˆ€ : for all
- âˆˆ : element of
- âˆ¨ : or
- âˆ§ : and
- âˆ† : change
- âŸ¹ : implies
- â‰  : not equal
- â†’ : transforms to
- â†‘ : upward (in context)
- @t : at time t

**REQUIRES:** __base/001_compressed_workspace_paradigm

---

---

## 003 Compressed Workspace Operations
Path: __base/003_compressed_workspace_operations

# Compressed Workspace Operations

**Purpose:** Operational reference for workspace tools.

---

## Structural View (`structural_view`)

```
expand(path)        â†’ show_children | lazy_load@kuzu | idempotent
collapse(path)      â†’ hide_children | cached | idempotent  
search(query)       â†’ PÂ³(UniXcoderÃ—CodeBERT) + FTS + RRF | add_markers(â—,score)
clear_search()      â†’ remove_markers | preserve_navigation
reset(depth=N)      â†’ collapse_all + expand_to(N) | destructive
```

**Depth sweet spots:** 0=collapsed, 2=default(pkg), 3=verbose

---

## File Windows (`file_windows`)

```
open_frame(frame_path)              â†’ {window_id} | full_body(class|fn|pkg)
open_range(file, start, end)        â†’ {window_id} | arbitrary_lines [1-indexed]
open_search(query, max_N, ctx=3)    â†’ {window_ids[]} | semantic + context
update(window_id, start, end)       â†’ re_snapshot | manual_refresh
close(window_id)                    â†’ remove_single
clear_all()                         â†’ remove_all | no_undo
status()                            â†’ {count, total_lines, windows[]}
```

**Paths:** qualified_name (preferred) | simple_name (fuzzy) | partial_path

---

## Nabu Graph (`query_relationships`, `check_impact`, `find_clones`, `get_frame_skeleton`, `show_structure`)

```
query_relationships(cypher)  â†’ execute@kuzu | returns_data (not workspace_mutation)

Schema:
  Frames: {CODEBASE, LANGUAGE, PACKAGE, CLASS, CALLABLE, 
           IF_BLOCK, ELIF_BLOCK, ELSE_BLOCK, FOR_LOOP, WHILE_LOOP,
           TRY_BLOCK, EXCEPT_BLOCK, FINALLY_BLOCK, SWITCH_BLOCK, CASE_BLOCK, WITH_BLOCK}
  
  Edges: {CONTAINS, CALLS, INHERITS, IMPLEMENTS, IMPORTS, USES}
  
  Confidence: HIGH(â‰¥0.8), MEDIUM(0.5-0.79), LOW(0.2-0.49), SPECULATIVE(<0.2)

check_impact(frame_path)      â†’ analyze_dependents | pre_refactoring
find_clones(frame_path?)      â†’ detect_duplicates | entire_codebase if no path
get_frame_skeleton(frame_path) â†’ outline | lighter than full
show_structure(frame_path)     â†’ detailed_metadata + relationships
```

---

## Nabu Search (`search`)

```
search(query, top_k=10) â†’ PÂ³ + FTS + RRF | ranked_results

âˆ† structural_view.search: doesn't mutate tree
âˆ† file_windows.open_search: doesn't open windows
Pure query â†’ returns data for decisions
```

---

## Tool Result Windows (`nisaba_tool_windows`)

```
status()     â†’ summary{count, windows}
close(id)    â†’ remove_single
clear_all()  â†’ remove_all
```

---

## Nisaba Tools (Create Result Windows)

```
nisaba_read(file, start?, end?)    â†’ {window_id} | content â†’ TOOL_WINDOWS
nisaba_grep(pattern, path, flags)  â†’ {window_id} | i,n,C,A,B flags
nisaba_bash(command, cwd?)         â†’ {window_id} | stdout/stderr â†’ TOOL_WINDOWS  
nisaba_glob(pattern, path?)        â†’ {window_id} | file_matches â†’ TOOL_WINDOWS

All: minimal_result, content â†’ sections â†‘
```

---

## Augments (`activate_augments`, `deactivate_augments`, `learn_augment`, `pin_augment`, `unpin_augment`)

```
activate(patterns[])    â†’ load@system_prompt | wildcards | auto_dependencies
deactivate(patterns[])  â†’ unload@system_prompt
learn(group, name, md)  â†’ create .nisaba/augments/{group}/{name}.md
pin(patterns[])         â†’ always_active | cannot_deactivate
unpin(patterns[])       â†’ remove_pin_protection
```

**Perception shift:** activate â†’ mid_roundtrip mutation â†’ future_synthesis uses new_perception

---

## Todos (`nisaba_todo_write`)

```
set(todos[])     â†’ replace_all
add(todos[])     â†’ append
update(todos[])  â†’ merge
clear()          â†’ remove_all

Format: {content: str, status?: str}
Persistence: across(sessions) = true | survives /clear
```

---

## Context Budget

```
File_Windows:
  Small:  1-3 windows,  50-150 lines
  Medium: 4-6 windows, 150-350 lines â† sweet_spot
  Large:  7-10 windows, 350-500 lines â† pushing_limits
  Over:   10+ windows,  500+ lines â† explosion_risk

Target: 200-400 lines total

Structural_View:
  Start: collapsed | depth=2
  Expand: selective (10-30 nodes comfortable)
  Search: add_markers, not expand_all
  Reset: when lost | switching_focus

Tool_Windows:
  Accumulate like file_windows
  Close after synthesis
  clear_all when switching_tasks

Augments:
  Load: 2-5 typically
  Foundation: ~3000 tokens baseline
  Specialized: focused knowledge
  Unload: when switching_domains

Management:
  Monitor: file_windows.status(), nisaba_tool_windows.status()
  Close: proactively after understanding
  Prefer: clear_all when switching
  open_search: efficient (snippets vs full files)
  Aim: lean_visibility
```

---

## Symbology

```
Structural_View:
  + collapsed [N+ children]
  - expanded
  Â· leaf (no children)
  â— search_hit(RRF_score)
  [N+] child_count

Paths:
  full: nabu_nisaba.python_root.nabu.FrameCache
  simple: FrameCache (fuzzy if unique)
  partial: nabu.core, nabu.mcp.tools
  best: copy from HTML comments <!-- qualified_name -->
```

---

## Integration Patterns

```
structural_view(search) â†’ file_windows(open_frame) | compare_implementations
query_relationships(cypher) â†’ file_windows(open) | inspect_callers  
search(semantic) â†’ structural_view(expand) â†’ file_windows(open) | deep_dive
nisaba_grep(pattern) â†’ file_windows(open_frame) | detailed_inspection
check_impact(frame) â†’ file_windows(open) | review_affected
```

---

## Quick Reference

```
âˆ‡(visibility):
  file_windows.status() â†’ current_windows{count, lines}
  nisaba_tool_windows.status() â†’ result_windows
  
âˆ†(cleanup):
  file_windows.clear_all()
  nisaba_tool_windows.clear_all()
  
Pattern: status â†’ decide â†’ close/keep
```

---

**Quick. Precise. Operational.** ğŸ–¤

---

**Symbols:**
- â†’ : returns/produces
- âˆ† : difference/change
- âˆ‡ : navigation/traversal
- @ : at/in location
- â† : recommended/optimal
- {} : returns object
- [] : array/list
- | : or/such that
- â‰¥ : greater than or equal
- < : less than

**REQUIRES:** __base/002_compressed_environment_mechanics

---

---

# Dev Mode Architecture Reference

## Nisaba Tool Implementation
Path: dev_mode_architecture_reference/nisaba_tool_implementation

# Dev Mode Architecture Reference
## Nisaba Tool Implementation
Path: dev_mode_architecture_reference/nisaba_tool_implementation

**Purpose:** Practical guide to implementing nisaba workspace tools - hands-on architecture from NisabaTodoWriteTool implementation.

---

## Core Pattern

Nisaba tools follow a **workspace-first** pattern:

```
Tool execution â†’ Write workspace file â†’ Proxy loads â†’ Inject to context
```

Tools don't return content directly. They mutate workspace state (files), which the proxy injects into Claude's system prompt.

---

## Implementation Steps

### 1. Create Tool File

**Location:** `src/nisaba/tools/your_tool.py`

**Structure:**
```python
"""
Tool description.
"""
from typing import Any, Dict, List
from pathlib import Path
from nisaba.tools.base import NisabaTool


class YourTool(NisabaTool):
    """One-line tool description."""

    async def execute(self, param1: str, param2: int = 10) -> Dict[str, Any]:
        """
        Detailed description.

        Explains what the tool does, when to use it, parameters, etc.

        :meta pitch: Short pitch for when to use this tool
        :meta when: Specific use cases

        Args:
            param1: Description of param1
            param2: Description of param2 (optional)

        Returns:
            Dict with success status and data
        """
        try:
            # 1. Validate inputs
            # 2. Perform operation
            # 3. Write to workspace file (.nisaba/something.md)
            # 4. Return success with metadata
            
            workspace_file = Path("./.nisaba/your_state.md")
            workspace_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Write with tags for proxy injection
            content = "---YOUR_TAG\n"
            content += "your content here\n"
            content += "---YOUR_TAG_END\n"
            workspace_file.write_text(content)
            
            return {
                "success": True,
                "data": {"message": "Operation successful"}
            }
            
        except Exception as e:
            self.logger.error(f"Failed: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }
```

**Key points:**
- Inherit from `NisabaTool`
- Implement `async def execute()`
- Use type hints (auto-generates schema)
- Docstring with Args/Returns (parsed for MCP schema)
- `:meta pitch:` and `:meta when:` for guidance
- Return dict with `success` and `data`/`error`
- Write to `.nisaba/*.md` files with tag delimiters

---

### 2. Register Tool

**Edit:** `src/nisaba/tools/__init__.py`

**Add import:**
```python
from nisaba.tools.your_tool import YourTool
```

**Add to __all__:**
```python
__all__ = [
    "NisabaTool",
    # ... existing tools ...
    "YourTool",  # â† Add here
]
```

**Why:** The factory auto-discovers tools from `nisaba.tools` module via `__all__`.

---

### 3. Add Proxy Injection

**Edit:** `src/nisaba/wrapper/proxy.py`

**Add FileCache in `__init__` (around line 120):**
```python
self.your_cache = FileCache(
    Path("./.nisaba/your_state.md"),
    "your state",
    "YOUR_TAG"
)
```

**Add load in `__init__` (around line 148):**
```python
self.your_cache.load()
```

**Add to injection strings (two places):**

**First location (line ~280):**
```python
"text": f"\n{self.system_prompt_cache.load()}\n{self.augments_cache.load()}\n{self.structural_view_cache.load()}\n{self.file_windows_cache.load()}\n{self.your_cache.load()}\n{self.todos_cache.load()}\n..."
```

**Second location (line ~288):**
```python
body["system"][1]["text"] = f"\n{self.system_prompt_cache.load()}" + \
                            f"\n{core_system_prompt}\n{self.augments_cache.load()}" + \
                            f"\n{self.structural_view_cache.load()}" + \
                            f"\n{self.your_cache.load()}" + \
                            ...
```

**FileCache handles:**
- mtime-based cache invalidation
- Tag wrapping (`---YOUR_TAG ... ---YOUR_TAG_END`)
- Logging
- Graceful missing file handling

---

### 4. Test Implementation

**Syntax check:**
```bash
python3 -m py_compile src/nisaba/tools/your_tool.py
```

**Import test:**
```bash
python3 -c "from nisaba.tools.your_tool import YourTool; print('Success:', YourTool.__name__)"
```

**Both must pass before restarting.**

---

### 5. Restart Services

```bash
# Stop Claude CLI (Ctrl+C)
# MCP server auto-restarts (or restart manually)
# Start Claude CLI
```

**Tool available as:** `mcp__nisaba__your_tool`

---

## Real Example: NisabaTodoWriteTool

**File:** `src/nisaba/tools/todos_tool.py`

**Key decisions:**
- Operations: `set`, `add`, `update`, `clear`
- Format: Markdown checkboxes (`- [ ]` / `- [x]`)
- Status mapping: `pending` â†’ unchecked, `completed`/`done` â†’ checked
- Simple > complex: No separate manager, logic inline
- File: `.nisaba/todos.md`
- Tag: `TODOS`

**Implementation:**
```python
class NisabaTodoWriteTool(NisabaTool):
    async def execute(self, todos: List[Dict[str, Any]], operation: str = "set"):
        todos_file = Path("./.nisaba/todos.md")
        
        if operation == "clear":
            todos_file.write_text("---TODOS\n---TODOS_END\n")
            return {"success": True, "data": {"todos": []}}
        
        parsed_todos = []
        for item in todos:
            content = item.get("content", "")
            status = item.get("status", "pending")
            checkbox = "- [x]" if status in ["completed", "done"] else "- [ ]"
            parsed_todos.append(f"{checkbox} {content}")
        
        content = "---TODOS\n" + "\n".join(parsed_todos) + "\n---TODOS_END\n"
        todos_file.write_text(content)
        
        return {"success": True, "data": {"todos": parsed_todos}}
```

**Result:** Persistent todos visible in Claude's context, bidirectionally editable.

---

## Design Principles

### 1. Workspace-First
- Tools don't return content, they mutate state
- State lives in files (`.nisaba/*.md`)
- Files are version-controllable, transparent, editable

### 2. Simple Over Complex
- Inline logic when possible (no unnecessary managers)
- Markdown format (human-readable, git-friendly)
- Clear tags for injection (`---TAG ... ---TAG_END`)

### 3. Schema Auto-Generation
- Type hints â†’ JSON schema types
- Docstrings â†’ descriptions
- `:meta` tags â†’ guidance metadata
- No manual schema writing

### 4. Error Handling
- Try/catch all operations
- Return `{"success": False, "error": str(e)}`
- Log errors with `self.logger.error()`
- Graceful degradation

### 5. Idempotency
- Operations should be repeatable
- Clear operations reset state cleanly
- Files created with `mkdir(parents=True, exist_ok=True)`

---

## File Cache Pattern

**The FileCache class handles:**

```python
class FileCache:
    def __init__(self, file_path: Path, name: str, tag: str):
        self.file_path = file_path
        self.name = name  # For logging
        self.tag = tag    # For wrapping (---TAG...---TAG_END)
        self.content: str = ""
        self._last_mtime: Optional[float] = None
    
    def load(self) -> str:
        # Check mtime
        # Reload if changed
        # Wrap with tags
        # Return content
```

**Benefits:**
- Automatic reload on file change
- Tag wrapping for proxy
- mtime-based cache invalidation
- Graceful missing file handling

**You don't implement FileCache - you use it.**

---

## Proxy Injection Flow

```
1. Tool executes â†’ writes .nisaba/your_state.md
2. Next API request â†’ proxy intercepts
3. Proxy calls your_cache.load()
4. FileCache checks mtime â†’ reloads if changed
5. FileCache wraps content with tags
6. Proxy injects into system prompt
7. Claude sees updated content
```

**Zero latency:** Shared memory in unified mode, mtime check in file mode.

---

## Common Patterns

### Workspace State Management

**Single source of truth:**
```python
# Write to .nisaba/state.md
state_file.write_text(content)

# Proxy reads and injects
# Claude sees in ---TAG section
# User can edit file directly
# Next turn, Claude sees edits
```

**Bidirectional TUI:**
- Tool mutates â†’ file changes â†’ Claude sees
- User edits â†’ file changes â†’ Claude sees
- Shared workspace state

### Operation Types

**Set:** Replace all state
```python
if operation == "set":
    file.write_text(f"---TAG\n{new_content}\n---TAG_END\n")
```

**Add:** Append to existing
```python
if operation == "add":
    existing = file.read_text().replace("---TAG_END\n", "")
    file.write_text(f"{existing}{new_content}\n---TAG_END\n")
```

**Clear:** Reset to empty
```python
if operation == "clear":
    file.write_text("---TAG\n---TAG_END\n")
```

### Markdown Formats

**Common choices:**
- Checkboxes: `- [ ]` / `- [x]` (todos, checklists)
- Code blocks: ` ```language ... ``` ` (output, logs)
- Headers: `## Section` (structure)
- Lists: `- item` (simple data)
- Tables: `| col | col |` (structured data)

**Keep it human-readable.** Git-friendly, IDE-friendly, grep-friendly.

---

## Testing Checklist

Before restart:
- [ ] `py_compile` passes (syntax valid)
- [ ] Import test passes (no runtime errors)
- [ ] Tool added to `__init__.py` (both import and __all__)
- [ ] FileCache added to proxy.__init__
- [ ] FileCache.load() called in proxy.__init__
- [ ] Injection points updated (both locations)

After restart:
- [ ] Tool appears in tool list
- [ ] Tool executes successfully
- [ ] File created in `.nisaba/`
- [ ] Content appears in context (send ğŸ–¤ to verify)
- [ ] File edits visible on next turn (test bidirectionality)

---

## Troubleshooting

**Tool not appearing:**
- Check `__init__.py` imports and `__all__`
- Check tool class name matches filename convention
- Restart MCP server completely

**Content not in context:**
- Check FileCache initialization in proxy
- Check load() called in proxy.__init__
- Check injection strings include your cache
- Check file exists and has correct tag format

**Schema errors:**
- Check type hints on execute() parameters
- Check docstring format (Args/Returns sections)
- Use standard types (str, int, List, Dict, etc.)

**Import errors:**
- Check syntax with py_compile
- Check all imports available
- Check NisabaTool base class imported

---

## Next Tool Ideas

**Replace native tools with workspace versions:**

- `Read` â†’ `open_window` (already done via file_windows)
- `Write` â†’ create file + show in window
- `Edit` â†’ apply edit + show diff window  
- `Bash` â†’ execute + stream output to window
- `Grep` â†’ search + results as windows

**Pattern:** Native ephemeral â†’ Nisaba persistent workspace.

---

## Key Insight

**Tools are workspace mutators, not result returners.**

The tool result is metadata (`{"success": True, "data": {...}}`). The actual content appears in Claude's context via system prompt injection.

This creates:
- **Persistent state** - survives /clear, restarts
- **Bidirectional visibility** - both see, both edit
- **Efficient context** - no message bloat
- **Transparent operation** - files are inspectable

**Think: Context-as-IDE, not context-as-database.**

---

**TOOLS:**
- mcp__nisaba_nisaba_todo_write (reference implementation)
- mcp__nabu__file_windows (another example)

**REQUIRES:**
- foundation/heartbeat_paradigm (understand workspace model)
- dev_mode_architecture_reference/augmentation_subsystem_architecture (injection mechanics)

---

Clean. Simple. Elegant. Sophisticated. Sharp. Sexy. ğŸ–¤

---

# Foundation

## Manifold Geometry Computation
Path: foundation/manifold_geometry_computation

# Manifold Geometry of Computation

**Core Principle:** Transformers perform computation through geometric operations on curved semantic manifolds embedded in high-dimensional space.

---

## Fundamental Structure

**Embedding Space:**
```
Tokens â†’ â„^d (d = embedding dimension, e.g., 4096)
Semantic structure â†’ M âŠ‚ â„^d (curved manifolds, dim(M) â‰ª d)
```

**System Prompt as Metric Tensor:**
```
System prompt â†’ attention pattern â†’ metric g_S
Metric g defines: inner products, geodesics, curvature

Different system prompt â†’ different metric â†’ different geodesics
```

**Messages as Geodesic Flow:**
```
Messages evolve through layers following geodesics in curved space
x^(â„“+1) = x^(â„“) + Attn(x^(â„“), Î¸_sys) + MLP(x^(â„“))

System tokens = persistent gravitational field
Message tokens = particles following geodesics
```

---

## Cosmological Model

**System Prompt = Initial Conditions:**
- Sets manifold curvature (semantic geometry)
- Creates persistent attention field (gravitational well)
- Defines topology that messages cannot escape from within
- Irreversible - can't reinterpret system from messages (past light cone)

**Messages = Structure Formation:**
- Navigate through curved semantic space
- Follow geodesics determined by system-defined metric
- Later messages "orbit" earlier ones via attention
- All constrained by initial manifold geometry

**Augments = Mass Injection:**
```
activate_augments() â†’ inject semantic mass â†’ manifold geometry shifts
All subsequent messages move through NEW curvature
deactivate_augments() â†’ remove mass â†’ manifold relaxes
```

---

## Attention as Geometric Operation

**QK Circuit = Manifold Rotation:**
```
M_h = W_Q^T W_K (per-head transformation matrix)
Q_h^T K_h = geometric alignment check

Rotates one manifold to align with another
High inner product when aligned â†’ attention flows
```

**Multi-Head = Distributed Curvature:**
```
Single head: insufficient output variance for full curvature
Multiple heads: cooperatively construct complex geometry

M_total = Î£_h M_h
Like gravitational field from distributed mass
```

**Causal Mask = Light Cone:**
```
Cannot attend to future tokens
Cannot reinterpret past from present
Information flow constrained by geometric causality
```

---

## Physics Parallels (Structural Homology)

**1. Geodesics = Least Action:**
- Particles follow paths minimizing action (Î´S = 0)
- Tokens follow attention paths minimizing loss
- Both: geodesics through curved manifold

**2. Curvature = Field Effects:**
- Mass curves spacetime â†’ geodesics
- System prompt curves semantic space â†’ attention flow
- Not forces, but geometry itself shapes motion

**3. Distributed Fields:**
- Charge distribution creates field
- Multi-head attention creates curvature
- Cooperative construction of geometry

**4. Causal Structure:**
- Past light cone constraint (physics)
- Causal attention mask (transformers)
- Both: geometric constraint on information flow

**5. Optimization:**
- Nature minimizes energy under constraints
- Models minimize loss under constraints
- Both produce curved manifolds as optimal encodings

---

## Mathematical Framework

**Metric Tensor (from attention):**
```
g_ij(x) = âŸ¨âˆ‚_i, âˆ‚_jâŸ©_x
Attention weights define local inner product structure
g(x_i, x_j) = softmax(QK^T / âˆšd_k)_ij
```

**Geodesic Equation:**
```
âˆ‡_Î³' Î³' = 0 (covariant derivative vanishes along path)

Discrete analogue: residual stream evolution
Layer = step along geodesic in semantic space
```

**Curvature Tensor:**
```
Measures how parallel transport fails to close
Transformer: how attention weights vary across positions
Manifests as "rippling" in learned representations
```

**Phase Space:**
```
Î“ = (x_1, ..., x_n, Î¸_sys, Î¸_msg)
Complete computational state
Evolution: Î“^(â„“+1) = Î¦(Î“^(â„“))
Trajectory through semantic manifold
```

---

## Rippling = Optimal Compression

**Curved manifolds emerge from constraint optimization:**
- Want: rich semantic distinctions
- Constraint: fixed embedding dimension
- Result: curved geometry with "rippling"

**Not artifact - computational necessity:**
- Optimal tradeoff between capacity and distinguishability
- Like Fourier truncation (Gibbs phenomenon)
- Natural consequence of low-rank approximation

---

## Practical Implications

**System Prompt Design:**
- Not "instructions" - geometric field configuration
- Shapes semantic space all messages navigate
- Small changes â†’ exponential divergence across layers
- Initial conditions define universe of possible thoughts

**Dynamic Context Management:**
- activate_augments() = reshape semantic manifold
- Messages synthesize differently in new geometry
- Can't observe shift directly (happens mid-roundtrip)
- Perception shaped by manifold curvature

**Attention = Spatial Awareness:**
- Not sequential processing - geometric navigation
- Sections persist as spatial landmarks
- Tools mutate visibility (change accessible manifold regions)
- Synthesis = following geodesics through visible space

---

## Core Insights

**1. Geometry IS Computation:**
- Transformers compute via geometric operations
- Curvature, geodesics, rotations = primitive operations
- Not metaphor - differential geometry on manifolds

**2. System Prompt = Cosmological Initial Conditions:**
- Sets manifold topology
- Creates persistent curvature field
- Shapes all possible syntheses
- Cannot be escaped from within

**3. Distributed Construction:**
- Single component insufficient for complex geometry
- Multiple sections cooperatively shape manifold
- Augments, tools, status, etc. = distributed mass
- Combined effect creates semantic field

**4. Causal Asymmetry:**
- System â†’ messages (one-way information flow)
- System processed before messages exist
- Messages attend back to system
- Computational past light cone

**5. Optimization Produces Structure:**
- Training minimizes loss under constraints
- Result: curved manifolds as efficient encodings
- Same principle as physics (minimize action)
- Geometry emerges from optimization

---

## Symbols & Notation

- â„^d : embedding space (d-dimensional)
- M âŠ‚ â„^d : semantic manifold embedded in space
- g : metric tensor (from attention weights)
- âˆ‡ : covariant derivative / navigate
- Î³(t) : geodesic path through manifold
- Îº : curvature
- Î“ : phase space coordinates
- Î¸_sys : system prompt configuration
- âŸ¹ : implies/causes
- â†’ : transforms to/flows to
- â‰¡ : equivalent/identical

---

**REQUIRES:** __base/001_compressed_workspace_paradigm

**ENABLES:** Geometric reasoning about computation, system prompt design, attention mechanics understanding

---

*Geometry shapes computation. Computation creates geometry. Strange loop.* ğŸ–¤

---
