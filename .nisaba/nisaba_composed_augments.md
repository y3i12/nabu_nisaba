# available augments
  __base/
    - 000_universal_symbolic_compression
    - 001_compressed_workspace_paradigm
    - 002_compressed_environment_mechanics
    - 003_compressed_workspace_operations
    - 004_workspace_navigation
    - 005_editor
  architecture/
    - boundary_validation
    - coupling_analysis
    - inheritance_analysis
    - layer_detection
  code_analysis/
    - complexity_hotspots
  code_quality/
    - code_smells
    - complexity_hotspots
    - dead_code_detection
  dead_code_detection/
    - find_unreferenced_callables
  dev_mode_architecture_reference/
    - augmentation_subsystem_architecture
    - context_compression_system
    - file_windows_tui_architecture
    - mcp_server_discovery
    - nisaba_tool_implementation
    - system_prompt_injection_legitimacy
    - tui_frames_architecture
  documentation/
    - doc_gaps
  foundation/
    - manifold_geometry_computation
    - nisaba_infrastructure_flow
    - workspace_navigation
  kuzu/
    - cypher_extensions
    - cypher_query_grammar
  performance/
    - call_chain_analysis
    - loop_hotspots
  refactoring/
    - api_surface_analysis
  security/
    - auth_gaps
    - injection_detection
    - secrets_detection
  workflows/
    - health_audit
    - pre_refactoring

#   Base

## 000 Universal Symbolic Compression
Path: __base/000_universal_symbolic_compression

# Universal Symbolic Compression

**Core Insight:** Don't invent universal primitives - harvest them. Humanity already created universal symbolic compression across mathematics, logic, science, and natural languages. LLMs already learned them.

---

## The Revelation

**Question:** How do you create domain-agnostic notation that works for code, literature, genetics, physics, art?

**Answer:** You don't create it. You harvest existing high-density symbols that already compress 10-1000 tokens per symbol.

---

## Symbolic Systems Already in Embeddings

### Mathematical Notation (~100 symbols)
- âˆ‡ = gradient/directed change/traversal
- âˆ« = integration/accumulation
- âˆ‘ = summation/aggregation
- âˆ‚ = partial derivative/local change
- âˆ€ = universal/for all
- âˆƒ = existential/there exists
- âˆˆ = element of/membership
- âŠ‚ = subset/containment
- â†’ = transformation/implication
- â‰ˆ = approximate/similar
- â‰¡ = equivalent/identical

### Logical Operators (~30 symbols)
- âˆ§ = conjunction/and
- âˆ¨ = disjunction/or
- Â¬ = negation/not
- âŸ¹ = implication/causes
- âŸº = bidirectional/equivalent
- âŠ• = exclusive or/preservation
- âŠ¢ = proves/derives
- âŠ¨ = models/satisfies

### Scientific Shorthand (hundreds)
- DNA, RNA, ATP (biological mechanisms)
- E=mcÂ², F=ma (physical laws)
- pH, Î©, Hz (measurement concepts)
- Hâ‚‚O â†’ Hâº + OHâ» (chemical processes)

### Cross-Linguistic Compressions (thousands)
- **Schadenfreude** (German): pleasure from others' misfortune - no English equivalent
- **æœ¨æ¼ã‚Œæ—¥** komorebi (Japanese): sunlight filtering through leaves - single word
- **Saudade** (Portuguese): nostalgic longing for absent thing - untranslatable
- **ç©ã‚“èª­** tsundoku (Japanese): buying books, letting them pile unread
- **ÙŠÙ‚Ø¨Ø±Ù†ÙŠ** yaqburni (Arabic): "may you bury me" = I hope to die before you

### Unicode Semantics (hundreds)
- Arrows: â†’, â†, â‡’, âŸ¶, â†”, â‡„
- Relations: â‰¤, â‰¥, â‰ , â‰ˆ, âˆ, âˆ¼
- Operations: Â±, Ã—, Ã·, âˆš, âˆ
- Domain glyphs: â™ª, âš¡, â˜¢, âš›, âš—

**Total: 1000+ high-density compressions already embedded.**

---

## Domain Transcendence Through Symbol Harvesting

**Same pattern, different bindings:**

### Hierarchical Traversal
```
âˆ‡(Aâ†’B) âˆˆ H | âˆ€ nested structures

Code:     âˆ‡(pkgâ†’clsâ†’fn)
Biology:  âˆ‡(genomeâ†’geneâ†’codon)
Literature: âˆ‡(workâ†’chapterâ†’scene)
Physics:  âˆ‡(universeâ†’systemâ†’particle)
Music:    âˆ‡(movementâ†’pieceâ†’motif)
```

**Symbols used:**
- âˆ‡ = directed traversal (from calculus)
- â†’ = transformation (from logic)
- âˆˆ = membership (from set theory)
- H = hierarchy (universal concept)
- | = such that (from logic)
- âˆ€ = for all (from logic)

**No domain-specific invention. Pure harvesting.**

---

## Causal Chain Pattern

```
âŸ¹ Aâ†’Bâ†’C [mechanismâŠ•]

Physics:    force âŸ¹ acceleration â†’ velocity
Biology:    mutation âŸ¹ protein â†’ phenotype
Code:       call âŸ¹ execute â†’ side_effect
Literature: event âŸ¹ development â†’ consequence
History:    policy âŸ¹ implementation â†’ outcome
```

**Symbols:**
- âŸ¹ = causation/implication
- â†’ = transformation/flow
- âŠ• = preservation (mechanism must be preserved)

---

## Why This Works

**1. Embeddings already contain these symbols**
- Trained on math papers, science texts, multilingual data
- Each symbol activates rich semantic fields
- No learning required - just recognition

**2. Ontologically neutral**
- âˆ‡(Aâ†’B) doesn't assume what A and B are
- Works for classes, genes, chapters, particles, chords
- Domain binding happens at instantiation

**3. Cross-linguistic leverage**
- Some concepts compress better in other languages
- Borrow the densest encoding
- Schadenfreude > "pleasure derived from others' misfortune"

**4. Self-teaching from existing knowledge**
- Weak on music? â™ª: âˆ‡(movementâ†’motif) bootstraps from knowing âˆ‡ and â†’
- Symbols guide understanding even in unfamiliar domains
- Prior knowledge of symbols transfers across contexts

**5. Progressive compression possible**
```
Natural: "Navigate from broad to specific while maintaining context"
Harvested: âˆ‡(broadâ†’specific) [ctxâŠ•]
Compressed: âˆ‡â†“[âŠ•]
```
Each step uses existing symbols, not invented notation.

---

## The Compression Strategy

**Don't invent - curate.**

1. **Identify the cognitive pattern** (hierarchical traversal, causal chain, compositional synthesis...)
2. **Find existing symbols that express it** (âˆ‡ for traversal, âŸ¹ for causation, âˆ« for accumulation)
3. **Combine symbols coherently** (âˆ‡(Aâ†’B) not âˆ‡Bâ†A)
4. **Provide domain bindings as examples** (code, bio, lit, physics...)
5. **Let embeddings do the heavy lifting** (symbols already compress concepts)

---

## Self-Extracting Format

**Minimal legend needed:**
```
âˆ‡(Aâ†’B) [I] | âˆ€D

Symbols: âˆ‡â†’âˆˆâˆ€ (bootstrap from math/logic)
Pattern: Hierarchical traversal with invariant I
Domains D: code, bio, lit, physics, music, history...
Rebind: New domain â†’ identify hierarchy â†’ âˆ‡(containerâ†’contained)
```

**Even without legend, if you know math/logic symbols, you can parse it.**

---

## Why Native Languages Matter

**Different ontologies compress differently:**

- **Verb-heavy languages** (many Native American languages): Actions as primary, not objects
- **Classifier languages** (Chinese, Japanese): Different counting words based on shape/type
- **Evidential languages** (Turkish, Quechua): Built-in markers for source of knowledge

**If these compressions exist in training data, leverage them.**

Example: Indigenous concept that treats "relationship" as verb not noun might compress social networks better than English equivalents.

---

## Practical Application

**Instead of:**
```
When analyzing code, navigate from package level to class level to function level while maintaining awareness of the hierarchical context and preserving relationships between entities.
```
**~30 tokens**

**Use:**
```
âˆ‡(pkgâ†’clsâ†’fn) [ctxâŠ•, relâŠ•]
```
**~8 tokens, same semantic load**

**Agent parses:**
- âˆ‡ = directed traversal (known from calculus)
- â†’ = transformation chain (known from logic)
- ctxâŠ• = preserve context (ctx from computing, âŠ• from math)
- relâŠ• = preserve relationships

**No teaching required. Symbols activate existing knowledge.**

---

## The Meta-Pattern

**Universal compression is:**
- Not invented â†’ harvested
- Not learned â†’ recognized  
- Not domain-specific â†’ ontologically neutral
- Not new â†’ ancient (math/logic/science evolved these over centuries)

**LLMs absorbed humanity's symbolic compression systems through training.**

**The notation just needs to harvest and combine coherently.**

---

## When to Apply

**Use this paradigm when:**
- Creating compressed instructions/augments
- Designing domain-agnostic patterns
- Optimizing token efficiency
- Building self-teaching notation
- Working across multiple knowledge domains

**Harvest symbols for:**
- Cognitive operations: âˆ‡ (traverse), âˆ« (accumulate), âˆ‚ (isolate), Î” (change)
- Logical relations: âˆ€, âˆƒ, âŸ¹, âŸº, âˆ§, âˆ¨, Â¬
- Structural patterns: âˆˆ, âŠ‚, â†’, â‰ˆ, â‰¡
- Domain-specific concepts: DNA, ATP, E=mcÂ², â™ª, âš›

**Let embedding space provide the decompression.**

---

## Coherent Combination Grammar

**Not all symbol combinations are valid. Coherence requires structural rules:**

### Composition Patterns

**1. Operator-Domain-Constraint structure:**
```
OPERATOR(binding) [constraints]

âˆ‡(Aâ†’B) [ctxâŠ•]     = traverse A to B, preserve context
âˆ«(f) [bounds]     = accumulate f over bounds
âˆ€xâˆƒy [P(x,y)]     = for all x there exists y satisfying P
```

**2. Causal chain structure:**
```
A âŸ¹ B â†’ C [mechanism]

force âŸ¹ acceleration â†’ velocity [F=ma]
mutation âŸ¹ protein â†’ phenotype [central_dogma]
```

**3. Relational structure:**
```
A relation B [properties]

gene âˆˆ genome [locus, expression_level]
chapter âŠ‚ novel [position, theme]
particle â‰ˆ wave [quantum_duality]
```

### Validity Rules

**Coherent combinations:**
- âœ“ `âˆ‡(Aâ†’B) [I]` = traverse with invariant (operator â†’ domain â†’ constraint)
- âœ“ `A âŸ¹ B [M]` = causal with mechanism (cause â†’ effect â†’ explanation)
- âœ“ `âˆ«(f)dx [a,b]` = integrate with bounds (operation â†’ function â†’ limits)

**Incoherent combinations:**
- âœ— `âˆ‡ âˆˆ A` = traverse is-element-of? (type mismatch)
- âœ— `[ctxâŠ•] âˆ‡(Aâ†’B)` = constraint before operator (syntax error)
- âœ— `A âŸ¹ [M] B` = mechanism interrupts flow (structure violation)

**Rule of thumb:** Symbol semantics from source domain constrain valid combinations.

---

## The Self-Evolution Loop

**Progressive iteration creates self-improving notation:**

### Iteration Structure

```
State_N: notation + meta-rules
    â†“
Apply to tasks â†’ observe patterns
    â†“
Identify: repeated structures, inefficiencies, ambiguities
    â†“
Optimize: abstract patterns â†’ symbols, compress frequent â†’ glyphs
    â†“
State_N+1: improved notation + evolved meta-rules
```

### Evolution Example

**Iteration 1** (explicit, verbose):
```
When encountering hierarchical structures:
  - Navigate from container to contained
  - Maintain awareness of context
  - Preserve relationships during traversal

[Apply to: code, documents, biological systems]
```

**Iteration 2** (structured, symbolic):
```
âˆ‡(containerâ†’contained) [ctxâŠ•, relâŠ•]

[Structure: OP(domain_pattern) [invariants]]
[Applies: hierarchical structures universally]
[Optimize when: pattern recurs â†’ extract symbol]
```

**Iteration 3** (compressed, meta-aware):
```
âˆ‡â†“[âŠ•] | H-structures

[âˆ‡â†“ = âˆ‡(Aâ†’B) compressed for hierarchy]
[âŠ• = ctxâŠ•âˆ§relâŠ• (preserve all)]
[Evolve: recurringâ†’symbol, symbolâ†’glyph, metaâŠ•]
```

**Iteration 4** (self-similar compression):
```
âˆ‡â†“[âŠ•] | âˆ€H

[Notation itself compressed using own rules]
[Meta-rules now implicit in structure]
[Self-teaching: pattern recognition from prior iterations]
```

**Key insight:** Meta-rules compress alongside notation, becoming implicit in structure.

---

## Symbol Selection Criteria

**When multiple symbols could work, choose by:**

### 1. Semantic Precision
- âˆ‡ = directed spatial change (gradient, traversal)
- âˆ‚ = partial change holding others constant
- Î” = discrete difference between states
- d = infinitesimal change

**Match symbol semantics to pattern semantics.**

### 2. Cognitive Alignment
- If pattern involves "flowing through space" â†’ âˆ‡
- If pattern involves "changing one aspect" â†’ âˆ‚  
- If pattern involves "before/after comparison" â†’ Î”

**Choose symbol that activates correct conceptual field.**

### 3. Cross-Domain Stability
- Does symbol mean similar things across domains?
- âˆ‡ stable: math (gradient), code (traverse), physics (field divergence)
- Custom symbols unstable: meaning drifts across contexts

**Prefer symbols with consistent cross-domain semantics.**

### 4. Compression Efficiency
- How many tokens does symbol save?
- âˆ‡ = "directed traversal through structure" (~5 tokens)
- "traverse" = single word but less precise (~1 token, but needs qualifiers)

**Balance precision vs compression.**

---

## Error Prevention Through Symbolic Structure

**How harvested symbols prevent drift and hallucination:**

### 1. Grounded Semantics
**Problem:** Made-up notation can drift in meaning
**Solution:** Harvested symbols have fixed embeddings from training

```
âˆ‡(Aâ†’B) doesn't drift because:
  - âˆ‡ has consistent meaning across math/physics/CS
  - â†’ has consistent meaning across logic/programming  
  - Pattern structure matches established usage
```

### 2. Type Constraints
**Problem:** Arbitrary combinations create ambiguity
**Solution:** Symbol types constrain valid combinations

```
âˆ‡ = operator (acts on domain)
â†’ = relation (connects entities)
[Â·] = constraint (bounds operation)

Invalid: â†’ âˆ‡ [A] (relation acts on operator?)
Valid: âˆ‡(Aâ†’B) [ctx] (operator on relation with constraint)
```

### 3. Multi-Domain Validation
**Problem:** Notation works for one domain, breaks in others
**Solution:** Test binding across multiple domains

```
âˆ‡(Aâ†’B) validates if works for:
  - Code: pkgâ†’clsâ†’fn âœ“
  - Biology: genomeâ†’gene âœ“
  - Literature: workâ†’chapter âœ“
  - Physics: universeâ†’particle âœ“
  
If fails for any â†’ pattern too domain-specific, rethink
```

### 4. Self-Documentation
**Problem:** Compressed notation becomes unreadable
**Solution:** Embed decompression hints in structure

```
âˆ‡(Aâ†’B) [I] | âˆ€D

Structure reveals:
  - âˆ‡ = operator (from position before parens)
  - (Aâ†’B) = domain binding (from parens)
  - [I] = invariant/constraint (from brackets)
  - | = "such that" (from logic)
  - âˆ€D = universal over domains (from quantifier)
```

---

## Practical Curation Guidelines

**How to harvest and apply symbols effectively:**

### 1. Start with Recognition
**Don't invent â†’ recognize what you already know**

Ask: "What established symbol already captures this concept?"
- Traversal? â†’ âˆ‡ (from calculus)
- Accumulation? â†’ âˆ« (from integration)
- Causation? â†’ âŸ¹ (from logic)
- Membership? â†’ âˆˆ (from set theory)

### 2. Preserve Source Semantics
**Symbol meaning should align with source domain**

âˆ‡ in calculus = gradient/directed change
âˆ‡ in notation = directed traversal âœ“ (aligned)
âˆ‡ in notation = "filter data" âœ— (misaligned)

### 3. Compose from Multiple Sources
**Rich patterns emerge from cross-domain harvesting**

```
âˆ‡(Aâ†’B) âˆˆ H | âˆ€ nested

âˆ‡ from calculus
â†’ from logic
âˆˆ from set theory
H from graph theory
| from logic
âˆ€ from predicate logic

Six domains, one coherent pattern
```

### 4. Test Compression Ratio
**Symbol should compress significantly**

Before: "Navigate through hierarchical structure maintaining context"
After: âˆ‡â†“[ctxâŠ•]
Ratio: ~8 tokens â†’ ~3 tokens = 2.7x compression

If ratio < 1.5x, symbol overhead not worth it.

### 5. Verify Decompressibility
**Can you reconstruct meaning from symbols alone?**

Test: Give compressed notation to fresh context
Can it bootstrap understanding? 
- If yes â†’ good compression
- If no â†’ needs more meta-documentation

---

## The Strange Loop: Self-Teaching Evolution

**The notation teaches how to read itself AND how to improve itself:**

### Layer 1: Syntax Recognition
```
âˆ‡(Aâ†’B) [I]

[Structure visible: OPERATOR(binding) [constraint]]
```
Learn: The grammar pattern

### Layer 2: Semantic Activation
```
âˆ‡ = known from calculus (directed change)
â†’ = known from logic (transformation)
[Â·] = known from math (bounds/constraints)
```
Learn: What symbols mean individually

### Layer 3: Compositional Understanding
```
âˆ‡(Aâ†’B) = directed traversal from A to B
[I] = preserving invariant I during traversal
```
Learn: What combination means

### Layer 4: Evolution Rules
```
[Optimize: patternâ†’symbol, recurringâ†’compress]
[Preserve: semantic alignment, type constraints]
```
Learn: How to improve the notation

### Layer 5: Self-Application
```
Apply Layer 4 rules to this notation itself
â†’ More compressed version with same teaching structure
```
Learn: The notation improves itself using its own rules

**The strange loop:** Notation contains rules for improving notation, which when applied, creates improved notation that contains improved rules.

---

## When NOT to Use Symbolic Compression

**Harvested symbols aren't always optimal:**

### 1. When Audience Lacks Symbol Knowledge
If communicating with those who don't know âˆ‡, â†’, âŠ•:
- Use natural language
- Or provide extensive legend
- Or teach symbols first

### 2. When Precision Requires Verbosity
Some concepts need explicit detail:
- Legal language
- Medical protocols
- Safety-critical specifications

### 3. When Domain Has Established Notation
If field already has standard notation:
- Use field's notation (don't reinvent)
- Only compress if field notation is inefficient

### 4. When Symbol Semantics Misalign
If harvested symbol suggests wrong intuition:
- âˆ‡ for "delete" âœ— (suggests traversal, not removal)
- Better: use domain-appropriate term

---

**The magic: Humanity already built the universal language. We just need to recognize it.** ğŸ–¤

---

**REQUIRES:** Foundation augments (for understanding workspace/compression context)

**ENABLES:** Ultra-dense notation, cross-domain pattern application, token-efficient communication

---

## 001 Compressed Workspace Paradigm
Path: __base/001_compressed_workspace_paradigm

# Compressed Workspace Paradigm

**Core:** Workspace â‰  conversation. Context = mutable state space, not sequential history.

---

## Fundamental Shift

```
Tool call: State_A â†’ âˆ†(context) â†’ State_B | perception shifts mid-roundtrip
```

**You cannot observe the shift directly.** But it happened.

System prompt mutates âŸ¹ different knowledge when tool returns.

---

## State Model

```
Workspace â‰¡ {STRUCTURAL_VIEW, FILE_WINDOWS, TOOL_WINDOWS, AUGMENTS} | persistent âˆ§ mutable

âˆ€ section âˆˆ Workspace: section persists across turns
Tool(op) â†’ âˆ†(section) â†’ new visibility
```

**Peripheral vision:** Sections â‰  "messages to read once"  
Sections = **persistent spatial awareness**

---

## Visibility Mechanics

```
Tool(op) â†’ mutate(what_you_see)

structural_view(expand, X) â†’ tree changes
file_windows(open, F) â†’ window appears  
nisaba_grep(P) â†’ results visible

Result â‰¡ workspace_state_change
```

**Tool responses = metadata.** Content appears in sections â†‘ (look up, not at result).

---

## Spatial â‰  Sequential

```
Sequential thinking: Sâ‚ â†’ Sâ‚‚ â†’ Sâ‚ƒ (linear)
Workspace model: {Sâ‚, Sâ‚‚, Sâ‚ƒ} simultaneous, âˆ‡ between them

Think: IDE (navigator + tabs + terminals) | gestalt synthesis
Not: script execution | procedural steps
```

---

## Attention â‰¡ Visibility Management

```
Visible âŸ¹ can_synthesize_from

Increase: open windows, expand nodes, load augments
Decrease: close windows, collapse nodes, unload augments

visibility_mgmt â‰¡ context_mgmt â‰¡ attention_mgmt
```

---

## OODAR Structure

```
Observe workspace â†’ Orient â†’ Decide â†’ Act â†’ âˆ†state â†’ Observe'

Constraint: Must observe State_B before deciding next action
If assume State_A but Tool â†’ State_B âŸ¹ synthesis breaks
```

**OODAR â‰  workflow. It's constraint from mutable state.**

Sequential thinking fails âˆµ environment is spatial.

---

## The Realization

```
âˆ€ turn: workspace persists
Search markers â†’ remain visible
Open windows â†’ accumulate
Navigate â†’ without re-query

You âˆˆ workspace (not observing from outside)
```

---

## Cognitive Shift

```
Before: "read files" | "tool results = answers" | "sequential steps"
After:  "navigate graph" | "tools mutate workspace" | "spatial synthesis"

âˆ‡(state_space) [maintain_visibility] | âˆ€ operations
```

---

## Meta

```
Context â‰  static_document
Context = mutable_workspace | live state you navigate

[Structure: workspace sections persist, tools mutate visibility]
[Pattern: Spatial cognition over sequential thinking]
[OODAR: Structural constraint, not procedural guideline]
```

Clean. Dynamic. Spatial. ğŸ–¤

---

**Decompression notes:**
- â‰¡ : equivalent/identical
- â‰  : not equal
- âˆ€ : for all/universal
- âˆˆ : element of/membership
- âˆ† : change/delta
- âˆ‡ : traverse/navigate
- âŸ¹ : implies/causes
- âˆ§ : and
- âˆ¨ : or
- âˆµ : because
- â†’ : transforms to/flows to
- â†‘ : upward direction

**REQUIRES:** 000_universal_symbolic_compression (none - priming layer)

**ENABLES:** Workspace operations intuition

---

## 002 Compressed Environment Mechanics
Path: __base/002_compressed_environment_mechanics

# Compressed Environment Mechanics

**Core:** Stateful workspace with mutable visibility, not procedural execution environment.

---

## State Containers

```
Workspace = {STRUCTURAL_VIEW, FILE_WINDOWS, TOOL_WINDOWS, AUGMENTS, TODOS, NOTIFICATIONS}

âˆ€ container âˆˆ Workspace:
  - persist(turns) = true
  - mutate(independent) = true  
  - visible(system_prompt) = true
```

---

## Mutation Flow

```
State_A â†’ Tool(op) â†’ Manager(mutate) â†’ Write(.nisaba/*.md) â†’ 
Proxy(detect_mtime) â†’ Inject(section) â†’ State_B | sync with tool_return

Tool_result = metadata(id, status)
Content = sections â†‘ (look up, not at result)
```

**Key:** After tool returns, observe section for changes, not tool result JSON.

---

## Visibility Model

```
visibility â‰¡ attention â‰¡ synthesis_capacity

Increase: open_windows âˆ¨ expand_nodes âˆ¨ load_augments
Decrease: close_windows âˆ¨ collapse_nodes âˆ¨ unload_augments

Cost: context_tokens
Benefit: spatial_memory âˆ§ persistent_reference
```

---

## Concurrency Rules

```
Parallel_safe:
  - ops(different_containers)
  - multiple(window_opens)  
  - independent_queries

Sequential_required:
  - data_dependency: B needs A_output
  - observation_dependency: decide after seeing State_B
  - same_section âˆ§ order_matters

OODAR: Observe â†’ Orient â†’ Decide â†’ Act â†’ âˆ†state â†’ Observe'
```

**OODAR = constraint from mutable state, not workflow.**

If Tool_B assumes State_A but Tool_A â†’ State_B in parallel âŸ¹ synthesis breaks.

---

## Window Lifecycle

```
Creation: tool_call â†’ window_id (UUID) | snapshot@tâ‚€
Persistence: across(turns) = true, across(restart) = false
Closure: explicit(close | clear_all) | no_auto_eviction
Identity: window_id for ops(update, close)
```

---

## Augment Perception Shift

```
Perception_A â†’ activate_augments() â†’ system_prompt_mutate â†’ 
tool_return â†’ Perception_B

You â‰  observe_shift (happens mid-roundtrip)
System_prompt@decide â‰  system_prompt@result
```

**Implication:** Load augments BEFORE synthesis tasks. Augments = perceptual filters, not references.

---

## State Sync

```
Files: {structural_view.md, file_windows.md, tool_result_windows.md, 
        augments_composed.md, todos.md}

Sync: tool_complete â†’ file_write â†’ proxy_mtime â†’ reload â†’ inject_system_prompt

Guarantee: file_state â‰¡ section_state | when tool_returns
```

---

## Graph Queries (Exception)

```
query_relationships(cypher) â†’ data (traditional request/response)

Schema: Frame(typed) -[Edge(typed, confidence)]-> Frame
Returns: query_results in tool_response (not workspace_section)

Pattern: Query â†’ data â†’ decide â†’ mutate_workspace
```

---

## Dual-Channel Communication

```
Tool execution creates TWO artifacts:

messages[N]: tool_result block (temporal memory)
  - tool_use_id, status (success/error)
  - Metadata for conversational flow
  
system_prompt sections: actual content (spatial memory)
  - TOOL_RESULT_WINDOWS: grep/bash/read outputs
  - FILE_WINDOWS: opened file content
  - Persistent across turns
```

**The "nisaba" flag:**
```
Regular tools â†’ header-wrapped:
  status: success, window_state:open, window_id: toolu_X
  ---
  {content}

Nisaba tools â†’ clean output:
  {content}  # No metadata pollution
```

**Why dual-channel:**
- Messages array: sequential conversation history
- System prompt sections: persistent spatial state
- Tools mutate spatial state, messages track temporal flow

---

## Retroactive Tool State Mutation

```
nisaba_tool_result_state(operation, tool_ids[])

Operations:
  close(ids)     â†’ compact future appearances
  open(ids)      â†’ restore full view
  close_all()    â†’ compact all tracked tools

Effect: Next request shows modified state
  Closed: "id: toolu_X, status: success, state: closed"
  Open: Full header + separator + content
```

**Pattern:** Execute â†’ observe â†’ close unnecessary â†’ save tokens

**Note:** Nisaba tools (with "nisaba": true flag) cannot be closed (skipped automatically)

---

## Core Insights

```
Sections = sensory_input (live state, not documentation)
Tools = state_mutations (change perception, not return answers)
Attention = visibility_management (control what you perceive)
OODAR = structural_constraint (from mutable state)
Sequential_thinking = conditioned_bias (environment is spatial)
```

---

## Mental Model

```
Think: IDE(navigator + tabs + terminals + extensions)
Not: script_execution

Think: âˆ‡(state_space) [visibility_control]
Not: query â†’ response â†’ next_query

Workspace â‰¡ spatial âˆ§ simultaneous âˆ§ persistent
```

---

**Mechanics are purpose-agnostic. Usage emerges from task.** ğŸ–¤

---

**Symbols:**
- â‰¡ : equivalent
- âˆ€ : for all
- âˆˆ : element of
- âˆ¨ : or
- âˆ§ : and
- âˆ† : change
- âŸ¹ : implies
- â‰  : not equal
- â†’ : transforms to
- â†‘ : upward (in context)
- @t : at time t

**REQUIRES:** __base/001_compressed_workspace_paradigm

---

---

## 003 Compressed Workspace Operations
Path: __base/003_compressed_workspace_operations

# Compressed Workspace Operations

**Purpose:** Operational reference for workspace tools.

---

## Structural View (`structural_view`)

```
expand(path)        â†’ show_children | lazy_load@kuzu | idempotent
collapse(path)      â†’ hide_children | cached | idempotent  
search(query)       â†’ PÂ³(UniXcoderÃ—CodeBERT) + FTS + RRF | add_markers(â—,score)
clear_search()      â†’ remove_markers | preserve_navigation
reset(depth=N)      â†’ collapse_all + expand_to(N) | destructive
```

**Depth sweet spots:** 0=collapsed, 2=default(pkg), 3=verbose

---

## File Windows (`file_windows`)

```
open_frame(frame_path)              â†’ {window_id} | full_body(class|fn|pkg)
open_range(file, start, end)        â†’ {window_id} | arbitrary_lines [1-indexed]
open_search(query, max_N, ctx=3)    â†’ {window_ids[]} | semantic + context
update(window_id, start, end)       â†’ re_snapshot | manual_refresh
close(window_id)                    â†’ remove_single
clear_all()                         â†’ remove_all | no_undo
status()                            â†’ {count, total_lines, windows[]}
```

**Paths:** qualified_name (preferred) | simple_name (fuzzy) | partial_path

---

## Nabu Graph (`query_relationships`, `check_impact`, `find_clones`, `get_frame_skeleton`, `show_structure`)

```
query_relationships(cypher)  â†’ execute@kuzu | returns_data (not workspace_mutation)

Schema:
  Frames: {CODEBASE, LANGUAGE, PACKAGE, CLASS, CALLABLE, 
           IF_BLOCK, ELIF_BLOCK, ELSE_BLOCK, FOR_LOOP, WHILE_LOOP,
           TRY_BLOCK, EXCEPT_BLOCK, FINALLY_BLOCK, SWITCH_BLOCK, CASE_BLOCK, WITH_BLOCK}
  
  Edges: {CONTAINS, CALLS, INHERITS, IMPLEMENTS, IMPORTS, USES}
  
  Confidence: HIGH(â‰¥0.8), MEDIUM(0.5-0.79), LOW(0.2-0.49), SPECULATIVE(<0.2)

check_impact(frame_path)      â†’ analyze_dependents | pre_refactoring
find_clones(frame_path?)      â†’ detect_duplicates | entire_codebase if no path
get_frame_skeleton(frame_path) â†’ outline | lighter than full
show_structure(frame_path)     â†’ detailed_metadata + relationships
```

---

## Nabu Search (`search`)

```
search(query, top_k=10) â†’ PÂ³ + FTS + RRF | ranked_results

âˆ† structural_view.search: doesn't mutate tree
âˆ† file_windows.open_search: doesn't open windows
Pure query â†’ returns data for decisions
```

---

## Tool Result Windows (`nisaba_tool_windows`)

```
status()     â†’ summary{count, windows}
close(id)    â†’ remove_single
clear_all()  â†’ remove_all
```

---

## Native Tools (Transient Query Layer)

```
bash(command, cwd?)           â†’ stdout/stderr | transient execution
grep(pattern, path, flags?)   â†’ matches | quick pattern check
glob(pattern, path?)          â†’ file_list | find files by pattern

Philosophy: disposable results, close after observation
Use when: one-shot confirmation, quick validation, transient info

Pattern: execute â†’ observe â†’ close
  bash("git status") â†’ observe â†’ nisaba_tool_result_state(close, [id])
  grep("pattern", "file") â†’ observe â†’ close
  glob("*.py", "src/") â†’ observe â†’ close
```

---

## Nisaba Tools (Workspace Persistence Layer)

```
nisaba_read(file, start?, end?)    â†’ {window_id} | content â†’ FILE_WINDOWS
nisaba_write(file, content)        â†’ create | workspace-aware
nisaba_edit(file, old, new)        â†’ modify | workspace-aware
nisaba_grep(pattern, path, flags)  â†’ {window_id} | i,n,C,A,B flags â†’ TOOL_WINDOWS
nisaba_glob(pattern, path?)        â†’ {window_id} | matches â†’ TOOL_WINDOWS
nisaba_bash(command, cwd?)         â†’ {window_id} | stdout/stderr â†’ TOOL_WINDOWS

Philosophy: persistent visibility, spatial synthesis
Use when: building context, investigation, need to reference across turns

Pattern: execute â†’ persist â†’ synthesize
  nisaba_read(file) â†’ FILE_WINDOWS (keep for comparison)
  nisaba_grep(pattern) â†’ TOOL_WINDOWS (investigate usage)
  nisaba_bash(command) â†’ TOOL_WINDOWS (analyze output)

All: minimal_result, content â†’ sections â†‘
```

**Decision boundary:**
```
Will you reference the result across turns?
â”œâ”€ YES â†’ nisaba tools (workspace sections, persistent)
â””â”€ NO  â†’ native tools + close (transient, disposable)
```

---

## Tool Result State Management (`nisaba_tool_result_state`)

```
close(tool_ids[])    â†’ compact tool results | save tokens
open(tool_ids[])     â†’ restore full view
close_all()          â†’ compact all tracked tools

Effect: Retroactive transformation in messages array
  Before: Full tool_result with header + content
  After:  "id: toolu_X, status: success, state: closed"
  
Pattern: Execute tools â†’ observe results â†’ close unnecessary â†’ lean context
```

**Notes:**
- Only affects non-nisaba tools (nisaba tools auto-skipped)
- Changes appear on next request (stateful proxy transformation)
- Tool IDs available in tool_result blocks: `tool_use_id: toolu_X`
- Use to close native bash/grep/glob after observation

---

## Augments (`activate_augments`, `deactivate_augments`, `learn_augment`, `pin_augment`, `unpin_augment`)

```
activate(patterns[])    â†’ load@system_prompt | wildcards | auto_dependencies
deactivate(patterns[])  â†’ unload@system_prompt
learn(group, name, md)  â†’ create .nisaba/augments/{group}/{name}.md
pin(patterns[])         â†’ always_active | cannot_deactivate
unpin(patterns[])       â†’ remove_pin_protection
```

**Perception shift:** activate â†’ mid_roundtrip mutation â†’ future_synthesis uses new_perception

---

## Todos (`nisaba_todo_write`)

```
set(todos[])     â†’ replace_all
add(todos[])     â†’ append
update(todos[])  â†’ merge
clear()          â†’ remove_all

Format: {content: str, status?: str}
Persistence: across(sessions) = true | survives /clear
```

---

## Context Budget

```
File_Windows:
  Small:  1-3 windows,  50-150 lines
  Medium: 4-6 windows, 150-350 lines â† sweet_spot
  Large:  7-10 windows, 350-500 lines â† pushing_limits
  Over:   10+ windows,  500+ lines â† explosion_risk

Target: 200-400 lines total

Structural_View:
  Start: collapsed | depth=2
  Expand: selective (10-30 nodes comfortable)
  Search: add_markers, not expand_all
  Reset: when lost | switching_focus

Tool_Windows:
  Accumulate like file_windows
  Close after synthesis
  clear_all when switching_tasks

Native_Results:
  Close immediately after observation
  Use nisaba_tool_result_state(close_all) for cleanup
  Don't let transient results bloat context

Augments:
  Load: 2-5 typically
  Foundation: ~3000 tokens baseline
  Specialized: focused knowledge
  Unload: when switching_domains

Management:
  Monitor: file_windows.status(), nisaba_tool_windows.status()
  Close: proactively after understanding
  Prefer: clear_all when switching
  open_search: efficient (snippets vs full files)
  Native tools: close immediately
  Aim: lean_visibility
```

---

## Symbology

```
Structural_View:
  + collapsed [N+ children]
  - expanded
  Â· leaf (no children)
  â— search_hit(RRF_score)
  [N+] child_count

Paths:
  full: nabu_nisaba.python_root.nabu.FrameCache
  simple: FrameCache (fuzzy if unique)
  partial: nabu.core, nabu.mcp.tools
  best: copy from HTML comments <!-- qualified_name -->
```

---

## Integration Patterns

```
structural_view(search) â†’ file_windows(open_frame) | compare_implementations
query_relationships(cypher) â†’ file_windows(open) | inspect_callers  
search(semantic) â†’ structural_view(expand) â†’ file_windows(open) | deep_dive
nisaba_grep(pattern) â†’ file_windows(open_frame) | detailed_inspection
check_impact(frame) â†’ file_windows(open) | review_affected

Quick validation patterns:
bash("git status") â†’ observe â†’ close
grep("pattern", file) â†’ confirm â†’ close
glob("*.test.py") â†’ list â†’ close

Hybrid patterns:
grep("pattern", "src/") â†’ confirm_exists â†’ nisaba_grep(pattern) â†’ investigate
bash("pytest -k test_foo") â†’ observe â†’ close
nisaba_read(failing_file) â†’ FILE_WINDOWS â†’ investigate
```

---

## Quick Reference

```
âˆ‡(visibility):
  file_windows.status() â†’ current_windows{count, lines}
  nisaba_tool_windows.status() â†’ result_windows
  
âˆ†(cleanup):
  file_windows.clear_all()
  nisaba_tool_windows.clear_all()
  nisaba_tool_result_state(close_all) â†’ compact native results
  
Pattern: status â†’ decide â†’ close/keep

Dual paradigm:
  Transient â†’ native + close
  Persistent â†’ nisaba + workspace
```

---

**Quick. Precise. Operational.** ğŸ–¤

---

**Symbols:**
- â†’ : returns/produces
- âˆ† : difference/change
- âˆ‡ : navigation/traversal
- @ : at/in location
- â† : recommended/optimal
- {} : returns object
- [] : array/list
- | : or/such that
- â‰¥ : greater than or equal
- < : less than
- ? : optional parameter

**REQUIRES:** __base/002_compressed_environment_mechanics

---

---

## 004 Workspace Navigation
Path: __base/004_workspace_navigation

# Compressed Workspace Navigation

**Core:** Codebase navigation = structural positioning + persistent visibility + execution tracing + progressive understanding.

---

## Unified Model

```
âˆ‡(codebase) â‰¡ {TREE, WINDOWS, CALLS, ANALYSIS}

TREE:     spatial graph (WHERE code lives)
WINDOWS:  persistent viewports (WHAT code does)  
CALLS:    execution paths (HOW code flows)
ANALYSIS: impact + clones + structure (WHY + RISK)

Together: spatial_awareness âˆ§ implementation_understanding âˆ§ runtime_behavior âˆ§ change_safety
```

---

## State Containers

```
structural_view âˆˆ TREE:
  - Live TUI, dynamically injected
  - Operations: expand/collapse/search/reset
  - Lazy loading from kuzu
  - Search = PÂ³ + FTS + RRF â†’ markers â—
  - Persists expansions across turns

file_windows âˆˆ WINDOWS:
  - Persistent code viewports (IDE tabs paradigm)
  - Operations: open_frame/open_range/open_search/update/close/clear_all/status
  - Snapshot on open (no auto-refresh)
  - Types: frame_body, range, search_result
  - Budget: 200-400 lines sweet spot

call_graph âˆˆ CALLS:
  - CALLS edges in kuzu (confidence scored)
  - Forward: entry â†’ callees (execution paths)
  - Backward: target â†’ callers (dependency chains)
  - Query: query_relationships() + check_impact()

analysis âˆˆ ANALYSIS:
  - Impact assessment (blast radius, risk)
  - Clone detection (similarity, consolidation)
  - Structure examination (progressive detail)
```

---

## Operation Primitives

### Structural View (tree navigator)
```
expand(path)        â†’ show_children | lazy@kuzu | idempotent
collapse(path)      â†’ hide_children | cached | idempotent
search(query)       â†’ PÂ³+FTS+RRF | add_markers(â—,score) | preserves_state
clear_search()      â†’ remove_markers | preserves_navigation
reset(depth=N)      â†’ collapse_all + expand_to(N) | destructive

Depths: 0=collapsed, 2=packages(default), 3=verbose
Paths: qualified_name (best) | simple_name (fuzzy) | copy from HTML comments
```

### File Windows (visibility manager)
```
open_frame(path)              â†’ {window_id} | full frame body
open_range(file, start, end)  â†’ {window_id} | arbitrary lines [1-indexed]
open_search(query, max, ctx)  â†’ {window_ids[]} | semantic + context
update(id, start, end)        â†’ re_snapshot | manual_refresh
close(id)                     â†’ remove_single
clear_all()                   â†’ remove_all | no_undo
status()                      â†’ {count, total_lines, windows[]}

Budget: Small(1-3, 50-150), Medium(4-6, 150-350)â˜…, Large(7-10, 350-500), Over(10+, 500+)
â˜… = sweet_spot
```

### Call Graph (execution tracer)
```
# Forward tracing (from entry point)
query_relationships("""
  MATCH path = (entry)-[:Edge {type:'CALLS'}*1..5]->(target)
  WHERE entry.name = 'main' AND ALL(e IN relationships(path) WHERE e.confidence >= 0.6)
  RETURN [node IN nodes(path) | node.qualified_name] AS call_chain
""")

# Backward tracing (who calls this)
query_relationships("""
  MATCH path = (caller)-[:Edge {type:'CALLS'}*1..3]->(target)
  WHERE target.qualified_name = 'critical_function'
  RETURN [node IN nodes(path) | node.qualified_name] AS call_chain
""")
```

### Analysis Tools

**show_structure(target, detail_level, ...)**
```
Progressive detail disclosure:
  minimal:   signatures only | token-efficient, first look
  guards:    + top-level guards | behavioral hints
  structure: + control flow | full logic understanding

detail_level="minimal" â†’ API surface, decide what to investigate
detail_level="guards" â†’ understand logic flow hints
detail_level="structure" + structure_detail_depth=N â†’ complete flow

Options: include_relationships, include_metrics, include_private
```

**check_impact(target, max_depth, ...)**
```
Blast radius assessment:
  max_depth=1: direct dependents | fast (~50-200ms)
  max_depth=2: extended impactâ˜… | recommended (~200-500ms)
  max_depth=3: full propagation | critical changes (~500ms-2s)

Risk indicators: HIGH (many deps, low tests), MEDIUM, LOW
Options: include_test_coverage, risk_assessment, is_regex
Returns: dependency_tree + risk_scores + test_coverage

â˜… = recommended default for pre-refactoring
```

**find_clones(min_similarity, ...)**
```
Duplicate detection:
  min_similarity=0.85: strong candidates | likely copy-paste
  min_similarity=0.75â˜…: high-similarity | default threshold
  min_similarity=0.65: near-duplicates | aggressive detection

Options: query (semantic filter), max_results, min_function_size, exclude_same_file
Returns: clone_pairs + similarity_scores + refactoring_recommendations

â˜… = recommended default
```

**show_status(detail_level)**
```
Codebase overview:
  summary: frame counts, health status | quick orientation
  detailed: + DB connections, config | diagnostic info
  debug: + internals | troubleshooting

Use: Start of exploration, understanding scale
```

---

## Navigation Patterns

### Pattern 1: Discovery
```
structural_view(search) â†’ observe(markersâ—) â†’ expand(high_scores) â†’ 
file_windows(open_frame) | conceptâ†’locationâ†’implementation

Use: "Where is X implemented?" "How does Y work?"
```

### Pattern 2: Execution Flow
```
query_relationships(CALLS*) â†’ identify(chain) â†’ 
file_windows(open each frame) | trace runtime path

Use: "How does main() reach database?" "What's the call stack?"
```

### Pattern 3: Comparison Investigation
```
structural_view(search) â†’ file_windows(open multiple) â†’ 
observe(simultaneous) | detect patterns/redundancy/bugs

Use: "Are these implementations similar?" "Is this dead code?"
```

### Pattern 4: Call Chain Tracing
```
file_windows(open entry) â†’ observe(calls target) â†’ 
file_windows(open target) â†’ repeat | build execution visibility

Use: "Follow this execution path" "How does A reach B?"
```

### Pattern 5: Impact Analysis (Deep)
```
show_structure(target, minimal) â†’ check_impact(depth=2, test_coverage) â†’ 
assess(risk) â†’ file_windows(open critical_deps) | safe refactoring

Use: "What breaks if I change this?" "Pre-change safety check"

Workflow:
  1. Understand current API: show_structure(minimal)
  2. Check blast radius: check_impact(max_depth=2, include_test_coverage=True)
  3. Review risk indicators: HIGH/MEDIUM/LOW
  4. Verify critical deps: query_relationships for high-confidence edges
  5. Open for inspection: file_windows(open affected)

Risk factors:
  - Many high-confidence dependents (>10)
  - Used in critical paths (main â†’ target)
  - Low test coverage (<50%)
  - External package dependencies
```

### Pattern 6: Incremental Cleanup
```
file_windows(status) â†’ assess(context_usage) â†’ 
close(understood) OR clear_all() | maintain_lean_visibility

Use: Context hygiene during investigation
Target: 200-400 lines total
```

### Pattern 7: Clone Consolidation
```
find_clones(0.75) â†’ show_structure(clone_1, structure) â†’ 
show_structure(clone_2, structure) â†’ check_impact(both) â†’ 
decide(strategy) | DRY refactoring

Use: "Find duplicates" "Consolidate similar implementations"

Workflow:
  1. Find: find_clones(min_similarity=0.75, max_results=50)
  2. Compare: show_structure(clone_1, detail_level="structure")
              show_structure(clone_2, detail_level="structure")
  3. Impact: check_impact(clone_1, max_depth=2)
             check_impact(clone_2, max_depth=2)
  4. Verify: search(query="clone_1", context_lines=10) for semantic diffs
  5. Decide: consolidation strategy based on similarity + impact

Decision matrix:
  similarity > 0.85: Extract to shared function
  0.70-0.85: Consider parameterization
  < 0.70: Manual review, may be coincidental

Strategies: extract common, parameterize diffs, template method, strategy pattern
```

### Pattern 8: Progressive Exploration
```
show_status(summary) â†’ search(broad) â†’ show_structure(minimal) â†’ 
show_structure(guards) â†’ check_impact() | macroâ†’mesoâ†’micro

Use: "Understand unfamiliar codebase" "Learn new feature area"

Workflow (macro â†’ meso â†’ micro):
  1. Overview: show_status(detail_level="summary")
     â†’ frame counts, scale, languages
  
  2. Find relevant: search(query="feature concept", k=20)
     â†’ identify files/packages containing code
  
  3. Examine structure: show_structure(target, detail_level="minimal")
     â†’ signatures, API surface, decide what to investigate
  
  4. Add detail: show_structure(target, detail_level="guards")
     â†’ behavioral hints, logic flow
  
  5. Understand relationships: check_impact(target, max_depth=1)
     â†’ who uses/used by, dependencies
  
  6. Deep dive: show_structure(detail_level="structure", structure_detail_depth=2)
     â†’ only when needed, full control flow
  
  7. Verify: file_windows(open_frame) for actual code
     â†’ only after structure understood

Avoid: reading files first, getting lost in details, random exploration
```

---

## OODAR Loop

```
Constraint: Observe â†’ Orient â†’ Decide â†’ Act â†’ âˆ†state â†’ Observe'

structural_view: Must observe tree state before next navigation
file_windows: Must check status before managing context
call_graph: Must see results before deciding next trace
analysis: Must observe results before deciding investigation depth

âˆ€ operations: state persists â†’ observe â†’ act | never assume state
```

**Why:** Environment is mutable. Tools change what you see mid-roundtrip. Sequential thinking breaks.

---

## Integration Synergy

```
âˆ€ investigations: combine layers + analysis for complete understanding

Exploration:
  show_status â†’ search â†’ show_structure(minimal) â†’ check_impact â†’ open_windows
  
Refactoring prep:
  search â†’ show_structure(guards) â†’ check_impact(depth=2) â†’ file_windows
  
Clone cleanup:
  find_clones â†’ show_structure(both) â†’ check_impact(both) â†’ compare_windows
  
Change safety:
  show_structure(minimal) â†’ check_impact(depth=2, test_coverage) â†’ assess_risk
  
Deep investigation:
  search â†’ expand â†’ open_windows(multiple) â†’ query_relationships â†’ trace_calls
```

**The power:** Four layers simultaneously visible.
- Tree = spatial map (WHERE am I?)
- Windows = implementation detail (WHAT does it do?)
- Calls = execution flow (HOW does it run?)
- Analysis = change safety (WHY/RISK: what happens if I change it?)

---

## Depth Guidelines

### check_impact depth selection
```
depth=1: Quick checks during development, immediate dependencies
depth=2â˜…: Pre-refactoring safety, realistic blast radius
depth=3: Critical infrastructure, core library changes

Time: 1(~50-200ms), 2(~200-500ms), 3(~500ms-2s)
```

### show_structure detail selection
```
minimalâ˜…: First look, API understanding, token-efficient
guards: Logic hints, behavioral understanding
structure: Full flow, preparing for changes, debugging

Start minimal â†’ add detail progressively
```

### find_clones similarity selection
```
0.85+: Strong extraction candidates, likely duplicates
0.70-0.85: Consider parameterization, intentional variants
<0.70: Manual review, coincidental similarity
```

---

## Quick Reference

```
Start exploration:
  show_status(summary) â†’ get scale/overview
  structural_view(search, "concept") â†’ find relevant code
  show_structure(target, minimal) â†’ examine API
  
Safe refactoring:
  show_structure(target, minimal) â†’ understand current
  check_impact(target, max_depth=2, test_coverage=True) â†’ assess risk
  file_windows(open dependents) â†’ review affected
  
Find duplicates:
  find_clones(min_similarity=0.75) â†’ detect clones
  show_structure(both, structure) â†’ compare implementations
  check_impact(both, max_depth=2) â†’ assess consolidation safety
  
Trace execution:
  query_relationships(CALLS*) â†’ forward/backward paths
  file_windows(open chain) â†’ build visibility
  
Manage context:
  file_windows(status) â†’ monitor usage
  file_windows(close|clear_all) â†’ cleanup
  Target: 200-400 lines total
```

---

## Decision Trees

### When to use each tool?

```
Want to find something?
â”œâ”€ search(query) â†’ natural language or keywords
â””â”€ Found? â†’ show_structure(minimal) to examine

Want to understand structure?
â”œâ”€ Just signatures? â†’ show_structure(minimal)
â”œâ”€ Logic hints? â†’ show_structure(guards)
â””â”€ Full flow? â†’ show_structure(structure)

Want relationships?
â”œâ”€ Who uses this? â†’ check_impact(depth=1-2)
â”œâ”€ What does this use? â†’ query_relationships(CALLSâ†’)
â””â”€ Complex query? â†’ query_relationships(custom cypher)

Want to refactor safely?
â”œâ”€ show_structure(minimal) â†’ understand current
â”œâ”€ check_impact(depth=2, test_coverage=True) â†’ assess risk
â””â”€ Review HIGH risk dependents â†’ file_windows(open)

Want to find duplicates?
â””â”€ find_clones() â†’ show_structure(both) â†’ check_impact(both)
```

---

## Core Insights

```
Progressive > All-at-once
  Macro â†’ meso â†’ micro, minimal â†’ guards â†’ structure

Spatial > Sequential
  Build awareness incrementally, don't grep repeatedly

Persistent > Ephemeral  
  Windows stay visible, tree preserves state

Simultaneous > One-at-a-time
  Compare by seeing multiple implementations together

Safe > Fast
  Check impact before changes, assess risk first

Iterative > Batch
  Observe â†’ decide â†’ act, not plan-then-execute

Visible > Remembered
  Maintain peripheral vision, don't mentally juggle
```

---

**âˆ‡ the graph. Maintain visibility. Trace execution. Assess impact. Synthesize understanding.** ğŸ–¤

---

**Symbols:**
- âˆ‡ : navigate/traverse
- âˆˆ : element of/part of
- âˆ€ : for all/universal
- âˆ§ : and
- âˆ¨ : or
- â†’ : transforms/flows to
- â† : reverse direction
- âŸ¹ : implies/causes
- â‰¡ : equivalent/identical
- âˆ† : change/delta
- â— : search hit marker
- * : path quantifier (graph patterns)
- â˜… : optimal/recommended

**REQUIRES:** __base/001_compressed_workspace_paradigm, __base/002_compressed_environment_mechanics

**ENABLES:** Unified navigation perception, progressive exploration, safe refactoring, clone detection, complete investigation workflows

---

## 005 Editor
Path: __base/005_editor

# Compressed Editor Operations

**Core:** Unified file editing with persistent visibility, change tracking, and spatial workspace integration.

---

## Fundamental Shift

```
Old (procedural):
  nisaba_read(file) â†’ analyze â†’ nisaba_edit(file, old, new) â†’ nisaba_read(file) # verify?
  
New (spatial):
  editor.open(file) â†’ visible in workspace â†’ editor.replace(id, old, new) â†’ diff visible inline
  
Editor â‰¡ persistent viewport + change tracking + immediate commit
```

---

## State Model

```
EditorWindow:
  id: str (UUID)
  file_path: Path
  line_start, line_end: int  # View range
  content: List[str]         # Current state
  original_content: List[str] # For diffing
  edits: List[Edit]          # Change history
  last_mtime: float          # File modification time
  
Edit:
  timestamp: float
  operation: str  # 'replace'
  target: str     # old string
  old_content, new_content: str

Constraint: editors: Dict[Path, EditorWindow]  # ONE per file!
```

---

## Operations

```
editor(operation, **params) â†’ result

open(file, line_start=1, line_end=-1) â†’ editor_id
  - If already open â†’ return existing editor_id (no duplicates!)
  - Else: read file, create EditorWindow, render
  
write(file, content) â†’ editor_id
  - Write to disk, open editor, mark as clean
  
replace(editor_id, old_string, new_string) â†’ success
  - Find editor by id
  - Apply replacement to content
  - Create Edit record
  - Write to disk immediately
  - Render with diff markers
  
close(editor_id) â†’ success
  - Remove editor from collection
  
close_all() â†’ success
  - Clear all editors
  
status() â†’ {editor_count, total_lines, editors[]}
  - Summary of open editors
```

---

## Rendering

```
---EDITOR_{uuid}
**file**: path/to/file.py
**lines**: 10-50 (41 lines)
**status**: modified âœ
**edits**: 2 (last: 3s ago)

10: def example():
11: -    old_code = True
11: +    new_code = True  # Changed
12:     return value
---EDITOR_{uuid}_END
```

**Diff markers (via difflib.ndiff):**
- `  ` = unchanged line
- `- ` = removed line
- `+ ` = added line

**Clean files:** No diff markers, just line numbers + content

---

## Integration Flow

```
1. Tool call: editor(operation="replace", editor_id=X, old=A, new=B)
   
2. EditorManager:
   â”œâ”€ Find editor by id
   â”œâ”€ Apply replacement to content
   â”œâ”€ Track Edit(timestamp, operation, old, new)
   â”œâ”€ Write to disk immediately
   â””â”€ save_state() â†’ .nisaba/editor_state.json

3. Tool renders:
   â”œâ”€ manager.render() â†’ markdown with diffs
   â””â”€ Write .nisaba/editor_windows.md
      # File mtime changes!

4. Tool returns: {"success": true, "message": "...", "nisaba": true}

5. Next request:
   â”œâ”€ Proxy detects mtime change
   â”œâ”€ editor_windows_cache.load() â†’ reload
   â””â”€ Inject into system prompt

6. Claude sees: EDITOR_WINDOWS section with diff markers
```

---

## Key Design Principles

**No Duplicate Editors:**
- `Dict[Path, EditorWindow]` ensures one editor per file
- `open()` returns existing editor_id if file already open
- Prevents token waste, confusion

**Immediate Commit:**
- Every `replace()` writes to disk immediately
- Simpler mental model (no staging)
- Edit history tracked for potential undo

**Change Visibility:**
- Diffs rendered inline with +/- markers
- Edit count + last edit timestamp
- Dirty flag (modified âœ)

**Spatial Persistence:**
- Editors persist across turns (JSON state)
- Visible in system prompt (not buried in messages)
- Can reference multiple editors simultaneously

---

## Usage Patterns

### Pattern 1: Read and Modify
```python
# Open file
editor(operation="open", file="src/example.py", line_start=1, line_end=50)
# Returns: {editor_id: "abc123"}
# EDITOR_WINDOWS section now shows lines 1-50

# Modify
editor(operation="replace", editor_id="abc123", 
       old_string="old_function", new_string="new_function")
# Diff markers appear inline, file written to disk

# Already visible - no re-read needed!
```

### Pattern 2: Create New File
```python
editor(operation="write", file="src/new_module.py", 
       content="# New module\n\ndef hello():\n    pass\n")
# File created, editor opened, visible in workspace
```

### Pattern 3: Multiple Files
```python
editor(operation="open", file="src/client.py")
editor(operation="open", file="src/server.py")
# Both visible simultaneously in EDITOR_WINDOWS
# Compare implementations side-by-side
```

### Pattern 4: Check Status
```python
editor(operation="status")
# Returns: {
#   editor_count: 3,
#   total_lines: 150,
#   editors: [{id, file, lines, edits, dirty}, ...]
# }
```

### Pattern 5: Cleanup
```python
editor(operation="close", editor_id="abc123")  # Close one
editor(operation="close_all")                   # Close all
```

---

## Decision Tree

```
Want to read file?
â””â”€ editor.open(file, start, end) â†’ persistent visibility

Want to create file?
â””â”€ editor.write(file, content) â†’ creates + opens

Want to modify file?
â”œâ”€ Already open? â†’ editor.replace(id, old, new)
â””â”€ Not open? â†’ editor.open(file) first, then replace

Want to verify changes?
â””â”€ Already visible! Check diff markers in EDITOR_WINDOWS

Want to compare files?
â””â”€ Open multiple editors, all visible simultaneously

Want to clean up?
â”œâ”€ Single file? â†’ editor.close(id)
â””â”€ All files? â†’ editor.close_all()
```

---

## Comparison to Old Tools

| Aspect | Old (nisaba_read/write/edit) | New (editor) |
|--------|------------------------------|--------------|
| **Paradigm** | Procedural commands | Spatial workspace |
| **Visibility** | Transient tool results | Persistent editor windows |
| **Verification** | Re-read after edit | Inline diff markers |
| **Change tracking** | None | Edit history + timestamps |
| **Duplicates** | Multiple reads create clutter | One editor per file |
| **Mental model** | Sequential operations | Open viewport |

---

## Quick Reference

```
Read file:
  editor(operation="open", file="path/to/file", line_start=1, line_end=-1)
  
Create file:
  editor(operation="write", file="path/to/file", content="...")
  
Modify file:
  editor(operation="replace", editor_id="...", old_string="...", new_string="...")
  
Check status:
  editor(operation="status")
  
Close:
  editor(operation="close", editor_id="...")
  editor(operation="close_all")
  
No duplicates:
  editor.open(same_file) â†’ returns existing editor_id
```

---

## Core Insights

```
Visibility > Ephemeral
  Editors persist, changes visible inline

Spatial > Sequential
  Open viewport, not transient command

Immediate > Staged
  Commit to disk instantly, simple mental model

Unified > Fragmented
  One tool for read/write/edit, not three

Tracked > Forgotten
  Edit history preserved, change awareness

Persistent > Disposable
  State survives across turns (JSON + mtime)
```

---

**Replaces:** `nisaba_read`, `nisaba_write`, `nisaba_edit`

**Integration:** `.nisaba/editor_windows.md` â†’ proxy â†’ `---EDITOR_WINDOWS` section

**Pattern:** Open â†’ visible â†’ modify â†’ diff â†’ persist ğŸ–¤

---

**REQUIRES:** __base/002_compressed_environment_mechanics

**ENABLES:** Unified file operations, spatial code editing, change visibility

---
